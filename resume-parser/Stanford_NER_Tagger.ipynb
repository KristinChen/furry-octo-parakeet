{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import textract, PyPDF2, glob\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('words')\n",
    "# nltk.download('stopwords')\n",
    "import re\n",
    "import os\n",
    "import subprocess\n",
    "from pdfminer.high_level import extract_text\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install textract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install textract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\rtd91\\anaconda3\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: Wand>=0.6.7 in c:\\users\\rtd91\\anaconda3\\lib\\site-packages (from pdfplumber) (0.6.7)\n",
      "Requirement already satisfied: Pillow>=8.4 in c:\\users\\rtd91\\anaconda3\\lib\\site-packages (from pdfplumber) (9.0.1)\n",
      "Requirement already satisfied: pdfminer.six==20211012 in c:\\users\\rtd91\\anaconda3\\lib\\site-packages (from pdfplumber) (20211012)\n",
      "Requirement already satisfied: chardet in c:\\users\\rtd91\\anaconda3\\lib\\site-packages (from pdfminer.six==20211012->pdfplumber) (3.0.4)\n",
      "Requirement already satisfied: cryptography in c:\\users\\rtd91\\anaconda3\\lib\\site-packages (from pdfminer.six==20211012->pdfplumber) (2.8)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in c:\\users\\rtd91\\anaconda3\\lib\\site-packages (from cryptography->pdfminer.six==20211012->pdfplumber) (1.14.0)\n",
      "Requirement already satisfied: six>=1.4.1 in c:\\users\\rtd91\\anaconda3\\lib\\site-packages (from cryptography->pdfminer.six==20211012->pdfplumber) (1.12.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rtd91\\anaconda3\\lib\\site-packages (from cffi!=1.11.3,>=1.8->cryptography->pdfminer.six==20211012->pdfplumber) (2.19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\rtd91\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(r\"C:\\Users\\rtd91\\Data\\Resume.pdf\")\n",
    "PATH_TO_JAR = \"C:\\\\Users\\rtd91\\Data\\stanford-ner.jar\"\n",
    "PATH_TO_MODEL = \"C:\\\\Users\\rtd91\\Data\\english.all.3class.distsim.crf.ser.gz\"\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "files1 = glob.glob(r\"C:\\Users\\rtd91\\Data\\resume_samples\\*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pdfplumber.open(files1[0]) as pdf:\n",
    "    first_page = pdf.pages[0]\n",
    "    txt = first_page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = StanfordNERTagger(model_filename=r\"C:\\Users\\rtd91\\Data\\english.all.3class.distsim.crf.ser.gz\",path_to_jar=r\"C:\\Users\\rtd91\\Data\\stanford-ner.jar\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pdfplumber.open(files1[0]) as pdf:\n",
    "    first_page = pdf.pages[0]\n",
    "    txt = first_page.extract_text()\n",
    "words = nltk.word_tokenize(txt) \n",
    "##removing stopwords and punctuations\n",
    "simple_strings = [word for word in words if word not in stopwords if word not in string.punctuation]\n",
    "res = [re.sub(r'[^\\w\\s]', '', word) for word in simple_strings]\n",
    "res1 = [re.sub(r'^abc(.*?)=[A-Z0-9]+(.*)', r'\\1\\2', word) for word in res]\n",
    "res2 = [str(res) for res in res1]\n",
    "res3 = [re.sub(r'/^[A-Za-z]+$/', '', res) for res in res2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Karthik', 'Ramanarayana', '2001', 'Eastern', 'Avenue', ',', 'Baltimore', ',', 'MD', '21231', 'Contact', 'No', ':', '(', '410', ')', '-292-1151', ';', 'Email', 'ID', ':', 'karthikr2194', '@', 'gmail.com', 'LinkedIn', ':', 'https', ':', '//www.linkedin.com/in/karthik-ramanarayana-77b4091b8', 'EDUCATION', 'University', 'of', 'Maryland', ',', 'Baltimore', 'County', ',', 'Baltimore', ',', 'Maryland', 'Dec', '2021', '(', 'Expected', ')', 'Master', 'of', 'Professional', 'Studies', 'in', 'Data', 'Science', ',', 'GPA', ':', '3.74', 'Bangalore', 'Institute', 'of', 'Technology', ',', 'Bangalore', ',', 'India', 'May', '2016', 'Bachelor', 'of', 'Engineering', 'in', 'Electronics', 'and', 'Communication', 'Engineering', 'SKILLS', 'Programming', ':', 'C', ',', 'Python', ',', 'SQL', ',', 'PySpark', 'Database', ':', 'MySQL', ',', 'PostgreSQL', ',', 'MongoDB', ',', 'HBase', 'Data', 'Skills', ':', 'Data', 'Visualization', ',', 'Data', 'Modelling', ',', 'Data', 'normalization', ',', 'Machine', 'Learning', ',', 'Data', 'Mining', ',', 'Statistics', 'Big', 'Data', ':', 'Hadoop', ',', 'Spark', ',', 'Hive', ',', 'Kafka', ',', 'Airflow', 'BI', 'Tools', ':', 'Tableau', ',', 'Power', 'BI', 'AWS', ':', 'S3', ',', 'Redshift', ',', 'Glue', ',', 'Athena', ',', 'Redshift', 'Spectrum', ',', 'QuickSight', 'Libraries', ':', 'Numpy', ',', 'Pandas', ',', 'Spacy', ',', 'NLTK', ',', 'Scikit-Learn', ',', 'Keras', 'Tools', 'and', 'Software', ':', 'Git', ',', 'MS', 'Excel', ',', 'MS', 'PowerPoint', ',', 'MS', 'Word', ',', 'SharePoint', ',', 'Jupyter', ',', 'Jira', 'WORK', 'EXPERIENCE', 'Data', 'Intern', ',', 'Index', 'Analytics', 'LLC', ',', 'Baltimore', ',', 'MD', 'January', '2021', '–', 'May', '2021', '•', 'Designed', 'and', 'created', 'a', 'database', 'based', 'on', 'Star', 'Schema', 'dimensional', 'modelling', 'for', 'Employee', 'Skills', 'Matrix', 'data', '.', '•', 'Transformed', 'and', 'cleaned', 'raw', 'data', 'using', 'Python', 'to', 'create', 'fact', 'and', 'dimension', 'tables', '.', '•', 'Built', 'an', 'executive', 'level', 'Power', 'BI', 'Dashboard', 'to', 'visualize', 'BI', 'Reports', 'of', 'Employee', 'Skills', 'data', ',', 'reducing', 'the', 'workload', 'by', '30', '%', '•', 'Led', 'and', 'managed', 'a', 'team', 'of', '3', 'by', 'following', 'Agile', 'methodology', 'using', 'Jira', 'tool', '.', 'Junior', 'Data', 'Engineer', ',', 'Accenture', ',', 'Bangalore', ',', 'India', 'July', '2018—July', '2019', '•', 'Implemented', 'ELT', 'Data', 'Pipeline', 'to', 'examine', 'user', 'behavior', 'for', 'a', 'music', 'streaming', 'client', 'company', '.', '•', 'Utilized', 'PySpark', 'to', 'improve', 'data', 'ingestion', 'and', 'processing', 'speed', 'by', '20', '%', '.', '•', 'Ingested', 'data', 'from', 'versatile', 'data', 'sources', 'like', 'RDBMS', ',', 'NOSQL', ',', 'APIs', 'and', 'loaded', 'it', 'to', 'a', 'Data', 'Lake', ',', 'as', 'a', 'central', 'repository', '.', '•', 'Developed', 'data', 'mappings', 'and', 'data', 'modelling', 'to', 'create', 'OLAP', 'databases', 'for', 'analytics', ',', 'ensuring', 'robust', 'data', 'quality', '.', 'Associate', 'Software', 'Engineer', ',', 'Accenture', ',', 'Bangalore', ',', 'India', 'November', '2016—June', '2018', '•', 'Developed', 'and', 'implemented', 'ABAP', 'programs', 'to', 'customize', 'SAP', 'transactions', 'using', 'OOPS', 'concepts', '.', '•', 'Devised', 'and', 'redesigned', 'custom', 'Reports', 'and', 'Smart', 'forms', 'which', 'enhanced', 'the', 'accuracy', 'of', 'the', 'ABAP', 'jobs', 'by', '30', '%', '.', '•', 'Identified', 'and', 'fixed', 'software', 'bugs', 'by', 'debugging', 'ABAP', 'programs', ',', 'decreasing', 'software', 'downtime', 'by', '15', '%', '.', 'ACADEMIC', 'PROJECTS', 'Sentiment', 'Analysis', 'of', 'Billboard', 'Top', '100', 'Songs', 'August', '-', 'October', '2020', '•', 'Collaborated', 'with', 'a', 'team', 'of', '5', 'to', 'analyze', 'the', 'mindset', 'of', 'each', 'year', 'using', 'Natural', 'language', 'Processing', 'of', 'song', 'lyrics', '.', '•', 'Language', ':', 'Python', ';', 'Libraries', ':', 'Pandas', ',', 'Gensim', ',', 'NLTK', ',', 'Spacy', '.', 'Movie', 'Recommendation', 'system', 'October', '-', 'November', '2020', '•', 'Recommended', 'new', 'movies', 'to', 'users', 'using', 'ALS', 'algorithm', 'with', 'a', 'root', 'mean', 'square', 'error', 'of', 'less', 'than', '0.9', '.', '•', 'Language', ':', 'Python', ';', 'Tools', ':', 'Apache', 'Spark', ';', 'Libraries', ':', 'Pandas', ',', 'Pyspark', '.', 'Human', 'Activity', 'Recognition', 'February', '–', 'March', '2019', '•', 'Designed', 'a', 'Machine', 'Learning', 'model', 'that', 'predicts', 'the', 'human', 'activities', 'such', 'as', 'Walking', ',', 'Walking', ',', 'etc.', ',', 'using', 'LSTM', 'algorithm', 'achieving', 'an', 'accuracy', 'of', '90.97', '%', '.', '•', 'Language', ':', 'Python', ';', 'Libraries', ':', 'Scikit-learn', ',', 'Keras', '.', 'LEADERSHIP/AWARDS', 'Mentor', ',', 'Accenture', 'June', '2018', 'Mentored', 'and', 'oversaw', 'a', 'team', 'of', '5', 'new', 'joiners', 'to', 'ensure', 'smooth', 'transition', 'to', 'the', 'team', ',', 'with', 'average', 'rating', 'of', '4.8', 'out', 'of', '5', '.', 'Alchemist', ',', 'Accenture', 'March', '2019', 'Awarded', '1st', 'prize', 'for', 'best', 'work', 'efficiency', ',', 'out', 'of', '500', 'employees', '.'] ['Karthik', 'Ramanarayana', '2001', 'Eastern', 'Avenue', 'Baltimore', 'MD', '21231', 'Contact', 'No', '410', '-292-1151', 'Email', 'ID', 'karthikr2194', 'gmail.com', 'LinkedIn', 'https', '//www.linkedin.com/in/karthik-ramanarayana-77b4091b8', 'EDUCATION', 'University', 'Maryland', 'Baltimore', 'County', 'Baltimore', 'Maryland', 'Dec', '2021', 'Expected', 'Master', 'Professional', 'Studies', 'Data', 'Science', 'GPA', '3.74', 'Bangalore', 'Institute', 'Technology', 'Bangalore', 'India', 'May', '2016', 'Bachelor', 'Engineering', 'Electronics', 'Communication', 'Engineering', 'SKILLS', 'Programming', 'C', 'Python', 'SQL', 'PySpark', 'Database', 'MySQL', 'PostgreSQL', 'MongoDB', 'HBase', 'Data', 'Skills', 'Data', 'Visualization', 'Data', 'Modelling', 'Data', 'normalization', 'Machine', 'Learning', 'Data', 'Mining', 'Statistics', 'Big', 'Data', 'Hadoop', 'Spark', 'Hive', 'Kafka', 'Airflow', 'BI', 'Tools', 'Tableau', 'Power', 'BI', 'AWS', 'S3', 'Redshift', 'Glue', 'Athena', 'Redshift', 'Spectrum', 'QuickSight', 'Libraries', 'Numpy', 'Pandas', 'Spacy', 'NLTK', 'Scikit-Learn', 'Keras', 'Tools', 'Software', 'Git', 'MS', 'Excel', 'MS', 'PowerPoint', 'MS', 'Word', 'SharePoint', 'Jupyter', 'Jira', 'WORK', 'EXPERIENCE', 'Data', 'Intern', 'Index', 'Analytics', 'LLC', 'Baltimore', 'MD', 'January', '2021', '–', 'May', '2021', '•', 'Designed', 'created', 'database', 'based', 'Star', 'Schema', 'dimensional', 'modelling', 'Employee', 'Skills', 'Matrix', 'data', '•', 'Transformed', 'cleaned', 'raw', 'data', 'using', 'Python', 'create', 'fact', 'dimension', 'tables', '•', 'Built', 'executive', 'level', 'Power', 'BI', 'Dashboard', 'visualize', 'BI', 'Reports', 'Employee', 'Skills', 'data', 'reducing', 'workload', '30', '•', 'Led', 'managed', 'team', '3', 'following', 'Agile', 'methodology', 'using', 'Jira', 'tool', 'Junior', 'Data', 'Engineer', 'Accenture', 'Bangalore', 'India', 'July', '2018—July', '2019', '•', 'Implemented', 'ELT', 'Data', 'Pipeline', 'examine', 'user', 'behavior', 'music', 'streaming', 'client', 'company', '•', 'Utilized', 'PySpark', 'improve', 'data', 'ingestion', 'processing', 'speed', '20', '•', 'Ingested', 'data', 'versatile', 'data', 'sources', 'like', 'RDBMS', 'NOSQL', 'APIs', 'loaded', 'Data', 'Lake', 'central', 'repository', '•', 'Developed', 'data', 'mappings', 'data', 'modelling', 'create', 'OLAP', 'databases', 'analytics', 'ensuring', 'robust', 'data', 'quality', 'Associate', 'Software', 'Engineer', 'Accenture', 'Bangalore', 'India', 'November', '2016—June', '2018', '•', 'Developed', 'implemented', 'ABAP', 'programs', 'customize', 'SAP', 'transactions', 'using', 'OOPS', 'concepts', '•', 'Devised', 'redesigned', 'custom', 'Reports', 'Smart', 'forms', 'enhanced', 'accuracy', 'ABAP', 'jobs', '30', '•', 'Identified', 'fixed', 'software', 'bugs', 'debugging', 'ABAP', 'programs', 'decreasing', 'software', 'downtime', '15', 'ACADEMIC', 'PROJECTS', 'Sentiment', 'Analysis', 'Billboard', 'Top', '100', 'Songs', 'August', 'October', '2020', '•', 'Collaborated', 'team', '5', 'analyze', 'mindset', 'year', 'using', 'Natural', 'language', 'Processing', 'song', 'lyrics', '•', 'Language', 'Python', 'Libraries', 'Pandas', 'Gensim', 'NLTK', 'Spacy', 'Movie', 'Recommendation', 'system', 'October', 'November', '2020', '•', 'Recommended', 'new', 'movies', 'users', 'using', 'ALS', 'algorithm', 'root', 'mean', 'square', 'error', 'less', '0.9', '•', 'Language', 'Python', 'Tools', 'Apache', 'Spark', 'Libraries', 'Pandas', 'Pyspark', 'Human', 'Activity', 'Recognition', 'February', '–', 'March', '2019', '•', 'Designed', 'Machine', 'Learning', 'model', 'predicts', 'human', 'activities', 'Walking', 'Walking', 'etc.', 'using', 'LSTM', 'algorithm', 'achieving', 'accuracy', '90.97', '•', 'Language', 'Python', 'Libraries', 'Scikit-learn', 'Keras', 'LEADERSHIP/AWARDS', 'Mentor', 'Accenture', 'June', '2018', 'Mentored', 'oversaw', 'team', '5', 'new', 'joiners', 'ensure', 'smooth', 'transition', 'team', 'average', 'rating', '4.8', '5', 'Alchemist', 'Accenture', 'March', '2019', 'Awarded', '1st', 'prize', 'best', 'work', 'efficiency', '500', 'employees'] ['Karthik', 'Ramanarayana', '2001', 'Eastern', 'Avenue', 'Baltimore', 'MD', '21231', 'Contact', 'No', '410', '2921151', 'Email', 'ID', 'karthikr2194', 'gmailcom', 'LinkedIn', 'https', 'wwwlinkedincominkarthikramanarayana77b4091b8', 'EDUCATION', 'University', 'Maryland', 'Baltimore', 'County', 'Baltimore', 'Maryland', 'Dec', '2021', 'Expected', 'Master', 'Professional', 'Studies', 'Data', 'Science', 'GPA', '374', 'Bangalore', 'Institute', 'Technology', 'Bangalore', 'India', 'May', '2016', 'Bachelor', 'Engineering', 'Electronics', 'Communication', 'Engineering', 'SKILLS', 'Programming', 'C', 'Python', 'SQL', 'PySpark', 'Database', 'MySQL', 'PostgreSQL', 'MongoDB', 'HBase', 'Data', 'Skills', 'Data', 'Visualization', 'Data', 'Modelling', 'Data', 'normalization', 'Machine', 'Learning', 'Data', 'Mining', 'Statistics', 'Big', 'Data', 'Hadoop', 'Spark', 'Hive', 'Kafka', 'Airflow', 'BI', 'Tools', 'Tableau', 'Power', 'BI', 'AWS', 'S3', 'Redshift', 'Glue', 'Athena', 'Redshift', 'Spectrum', 'QuickSight', 'Libraries', 'Numpy', 'Pandas', 'Spacy', 'NLTK', 'ScikitLearn', 'Keras', 'Tools', 'Software', 'Git', 'MS', 'Excel', 'MS', 'PowerPoint', 'MS', 'Word', 'SharePoint', 'Jupyter', 'Jira', 'WORK', 'EXPERIENCE', 'Data', 'Intern', 'Index', 'Analytics', 'LLC', 'Baltimore', 'MD', 'January', '2021', '', 'May', '2021', '', 'Designed', 'created', 'database', 'based', 'Star', 'Schema', 'dimensional', 'modelling', 'Employee', 'Skills', 'Matrix', 'data', '', 'Transformed', 'cleaned', 'raw', 'data', 'using', 'Python', 'create', 'fact', 'dimension', 'tables', '', 'Built', 'executive', 'level', 'Power', 'BI', 'Dashboard', 'visualize', 'BI', 'Reports', 'Employee', 'Skills', 'data', 'reducing', 'workload', '30', '', 'Led', 'managed', 'team', '3', 'following', 'Agile', 'methodology', 'using', 'Jira', 'tool', 'Junior', 'Data', 'Engineer', 'Accenture', 'Bangalore', 'India', 'July', '2018July', '2019', '', 'Implemented', 'ELT', 'Data', 'Pipeline', 'examine', 'user', 'behavior', 'music', 'streaming', 'client', 'company', '', 'Utilized', 'PySpark', 'improve', 'data', 'ingestion', 'processing', 'speed', '20', '', 'Ingested', 'data', 'versatile', 'data', 'sources', 'like', 'RDBMS', 'NOSQL', 'APIs', 'loaded', 'Data', 'Lake', 'central', 'repository', '', 'Developed', 'data', 'mappings', 'data', 'modelling', 'create', 'OLAP', 'databases', 'analytics', 'ensuring', 'robust', 'data', 'quality', 'Associate', 'Software', 'Engineer', 'Accenture', 'Bangalore', 'India', 'November', '2016June', '2018', '', 'Developed', 'implemented', 'ABAP', 'programs', 'customize', 'SAP', 'transactions', 'using', 'OOPS', 'concepts', '', 'Devised', 'redesigned', 'custom', 'Reports', 'Smart', 'forms', 'enhanced', 'accuracy', 'ABAP', 'jobs', '30', '', 'Identified', 'fixed', 'software', 'bugs', 'debugging', 'ABAP', 'programs', 'decreasing', 'software', 'downtime', '15', 'ACADEMIC', 'PROJECTS', 'Sentiment', 'Analysis', 'Billboard', 'Top', '100', 'Songs', 'August', 'October', '2020', '', 'Collaborated', 'team', '5', 'analyze', 'mindset', 'year', 'using', 'Natural', 'language', 'Processing', 'song', 'lyrics', '', 'Language', 'Python', 'Libraries', 'Pandas', 'Gensim', 'NLTK', 'Spacy', 'Movie', 'Recommendation', 'system', 'October', 'November', '2020', '', 'Recommended', 'new', 'movies', 'users', 'using', 'ALS', 'algorithm', 'root', 'mean', 'square', 'error', 'less', '09', '', 'Language', 'Python', 'Tools', 'Apache', 'Spark', 'Libraries', 'Pandas', 'Pyspark', 'Human', 'Activity', 'Recognition', 'February', '', 'March', '2019', '', 'Designed', 'Machine', 'Learning', 'model', 'predicts', 'human', 'activities', 'Walking', 'Walking', 'etc', 'using', 'LSTM', 'algorithm', 'achieving', 'accuracy', '9097', '', 'Language', 'Python', 'Libraries', 'Scikitlearn', 'Keras', 'LEADERSHIPAWARDS', 'Mentor', 'Accenture', 'June', '2018', 'Mentored', 'oversaw', 'team', '5', 'new', 'joiners', 'ensure', 'smooth', 'transition', 'team', 'average', 'rating', '48', '5', 'Alchemist', 'Accenture', 'March', '2019', 'Awarded', '1st', 'prize', 'best', 'work', 'efficiency', '500', 'employees'] ['Karthik', 'Ramanarayana', '2001', 'Eastern', 'Avenue', 'Baltimore', 'MD', '21231', 'Contact', 'No', '410', '2921151', 'Email', 'ID', 'karthikr2194', 'gmailcom', 'LinkedIn', 'https', 'wwwlinkedincominkarthikramanarayana77b4091b8', 'EDUCATION', 'University', 'Maryland', 'Baltimore', 'County', 'Baltimore', 'Maryland', 'Dec', '2021', 'Expected', 'Master', 'Professional', 'Studies', 'Data', 'Science', 'GPA', '374', 'Bangalore', 'Institute', 'Technology', 'Bangalore', 'India', 'May', '2016', 'Bachelor', 'Engineering', 'Electronics', 'Communication', 'Engineering', 'SKILLS', 'Programming', 'C', 'Python', 'SQL', 'PySpark', 'Database', 'MySQL', 'PostgreSQL', 'MongoDB', 'HBase', 'Data', 'Skills', 'Data', 'Visualization', 'Data', 'Modelling', 'Data', 'normalization', 'Machine', 'Learning', 'Data', 'Mining', 'Statistics', 'Big', 'Data', 'Hadoop', 'Spark', 'Hive', 'Kafka', 'Airflow', 'BI', 'Tools', 'Tableau', 'Power', 'BI', 'AWS', 'S3', 'Redshift', 'Glue', 'Athena', 'Redshift', 'Spectrum', 'QuickSight', 'Libraries', 'Numpy', 'Pandas', 'Spacy', 'NLTK', 'ScikitLearn', 'Keras', 'Tools', 'Software', 'Git', 'MS', 'Excel', 'MS', 'PowerPoint', 'MS', 'Word', 'SharePoint', 'Jupyter', 'Jira', 'WORK', 'EXPERIENCE', 'Data', 'Intern', 'Index', 'Analytics', 'LLC', 'Baltimore', 'MD', 'January', '2021', '', 'May', '2021', '', 'Designed', 'created', 'database', 'based', 'Star', 'Schema', 'dimensional', 'modelling', 'Employee', 'Skills', 'Matrix', 'data', '', 'Transformed', 'cleaned', 'raw', 'data', 'using', 'Python', 'create', 'fact', 'dimension', 'tables', '', 'Built', 'executive', 'level', 'Power', 'BI', 'Dashboard', 'visualize', 'BI', 'Reports', 'Employee', 'Skills', 'data', 'reducing', 'workload', '30', '', 'Led', 'managed', 'team', '3', 'following', 'Agile', 'methodology', 'using', 'Jira', 'tool', 'Junior', 'Data', 'Engineer', 'Accenture', 'Bangalore', 'India', 'July', '2018July', '2019', '', 'Implemented', 'ELT', 'Data', 'Pipeline', 'examine', 'user', 'behavior', 'music', 'streaming', 'client', 'company', '', 'Utilized', 'PySpark', 'improve', 'data', 'ingestion', 'processing', 'speed', '20', '', 'Ingested', 'data', 'versatile', 'data', 'sources', 'like', 'RDBMS', 'NOSQL', 'APIs', 'loaded', 'Data', 'Lake', 'central', 'repository', '', 'Developed', 'data', 'mappings', 'data', 'modelling', 'create', 'OLAP', 'databases', 'analytics', 'ensuring', 'robust', 'data', 'quality', 'Associate', 'Software', 'Engineer', 'Accenture', 'Bangalore', 'India', 'November', '2016June', '2018', '', 'Developed', 'implemented', 'ABAP', 'programs', 'customize', 'SAP', 'transactions', 'using', 'OOPS', 'concepts', '', 'Devised', 'redesigned', 'custom', 'Reports', 'Smart', 'forms', 'enhanced', 'accuracy', 'ABAP', 'jobs', '30', '', 'Identified', 'fixed', 'software', 'bugs', 'debugging', 'ABAP', 'programs', 'decreasing', 'software', 'downtime', '15', 'ACADEMIC', 'PROJECTS', 'Sentiment', 'Analysis', 'Billboard', 'Top', '100', 'Songs', 'August', 'October', '2020', '', 'Collaborated', 'team', '5', 'analyze', 'mindset', 'year', 'using', 'Natural', 'language', 'Processing', 'song', 'lyrics', '', 'Language', 'Python', 'Libraries', 'Pandas', 'Gensim', 'NLTK', 'Spacy', 'Movie', 'Recommendation', 'system', 'October', 'November', '2020', '', 'Recommended', 'new', 'movies', 'users', 'using', 'ALS', 'algorithm', 'root', 'mean', 'square', 'error', 'less', '09', '', 'Language', 'Python', 'Tools', 'Apache', 'Spark', 'Libraries', 'Pandas', 'Pyspark', 'Human', 'Activity', 'Recognition', 'February', '', 'March', '2019', '', 'Designed', 'Machine', 'Learning', 'model', 'predicts', 'human', 'activities', 'Walking', 'Walking', 'etc', 'using', 'LSTM', 'algorithm', 'achieving', 'accuracy', '9097', '', 'Language', 'Python', 'Libraries', 'Scikitlearn', 'Keras', 'LEADERSHIPAWARDS', 'Mentor', 'Accenture', 'June', '2018', 'Mentored', 'oversaw', 'team', '5', 'new', 'joiners', 'ensure', 'smooth', 'transition', 'team', 'average', 'rating', '48', '5', 'Alchemist', 'Accenture', 'March', '2019', 'Awarded', '1st', 'prize', 'best', 'work', 'efficiency', '500', 'employees'] ['Karthik', 'Ramanarayana', '2001', 'Eastern', 'Avenue', 'Baltimore', 'MD', '21231', 'Contact', 'No', '410', '2921151', 'Email', 'ID', 'karthikr2194', 'gmailcom', 'LinkedIn', 'https', 'wwwlinkedincominkarthikramanarayana77b4091b8', 'EDUCATION', 'University', 'Maryland', 'Baltimore', 'County', 'Baltimore', 'Maryland', 'Dec', '2021', 'Expected', 'Master', 'Professional', 'Studies', 'Data', 'Science', 'GPA', '374', 'Bangalore', 'Institute', 'Technology', 'Bangalore', 'India', 'May', '2016', 'Bachelor', 'Engineering', 'Electronics', 'Communication', 'Engineering', 'SKILLS', 'Programming', 'C', 'Python', 'SQL', 'PySpark', 'Database', 'MySQL', 'PostgreSQL', 'MongoDB', 'HBase', 'Data', 'Skills', 'Data', 'Visualization', 'Data', 'Modelling', 'Data', 'normalization', 'Machine', 'Learning', 'Data', 'Mining', 'Statistics', 'Big', 'Data', 'Hadoop', 'Spark', 'Hive', 'Kafka', 'Airflow', 'BI', 'Tools', 'Tableau', 'Power', 'BI', 'AWS', 'S3', 'Redshift', 'Glue', 'Athena', 'Redshift', 'Spectrum', 'QuickSight', 'Libraries', 'Numpy', 'Pandas', 'Spacy', 'NLTK', 'ScikitLearn', 'Keras', 'Tools', 'Software', 'Git', 'MS', 'Excel', 'MS', 'PowerPoint', 'MS', 'Word', 'SharePoint', 'Jupyter', 'Jira', 'WORK', 'EXPERIENCE', 'Data', 'Intern', 'Index', 'Analytics', 'LLC', 'Baltimore', 'MD', 'January', '2021', '', 'May', '2021', '', 'Designed', 'created', 'database', 'based', 'Star', 'Schema', 'dimensional', 'modelling', 'Employee', 'Skills', 'Matrix', 'data', '', 'Transformed', 'cleaned', 'raw', 'data', 'using', 'Python', 'create', 'fact', 'dimension', 'tables', '', 'Built', 'executive', 'level', 'Power', 'BI', 'Dashboard', 'visualize', 'BI', 'Reports', 'Employee', 'Skills', 'data', 'reducing', 'workload', '30', '', 'Led', 'managed', 'team', '3', 'following', 'Agile', 'methodology', 'using', 'Jira', 'tool', 'Junior', 'Data', 'Engineer', 'Accenture', 'Bangalore', 'India', 'July', '2018July', '2019', '', 'Implemented', 'ELT', 'Data', 'Pipeline', 'examine', 'user', 'behavior', 'music', 'streaming', 'client', 'company', '', 'Utilized', 'PySpark', 'improve', 'data', 'ingestion', 'processing', 'speed', '20', '', 'Ingested', 'data', 'versatile', 'data', 'sources', 'like', 'RDBMS', 'NOSQL', 'APIs', 'loaded', 'Data', 'Lake', 'central', 'repository', '', 'Developed', 'data', 'mappings', 'data', 'modelling', 'create', 'OLAP', 'databases', 'analytics', 'ensuring', 'robust', 'data', 'quality', 'Associate', 'Software', 'Engineer', 'Accenture', 'Bangalore', 'India', 'November', '2016June', '2018', '', 'Developed', 'implemented', 'ABAP', 'programs', 'customize', 'SAP', 'transactions', 'using', 'OOPS', 'concepts', '', 'Devised', 'redesigned', 'custom', 'Reports', 'Smart', 'forms', 'enhanced', 'accuracy', 'ABAP', 'jobs', '30', '', 'Identified', 'fixed', 'software', 'bugs', 'debugging', 'ABAP', 'programs', 'decreasing', 'software', 'downtime', '15', 'ACADEMIC', 'PROJECTS', 'Sentiment', 'Analysis', 'Billboard', 'Top', '100', 'Songs', 'August', 'October', '2020', '', 'Collaborated', 'team', '5', 'analyze', 'mindset', 'year', 'using', 'Natural', 'language', 'Processing', 'song', 'lyrics', '', 'Language', 'Python', 'Libraries', 'Pandas', 'Gensim', 'NLTK', 'Spacy', 'Movie', 'Recommendation', 'system', 'October', 'November', '2020', '', 'Recommended', 'new', 'movies', 'users', 'using', 'ALS', 'algorithm', 'root', 'mean', 'square', 'error', 'less', '09', '', 'Language', 'Python', 'Tools', 'Apache', 'Spark', 'Libraries', 'Pandas', 'Pyspark', 'Human', 'Activity', 'Recognition', 'February', '', 'March', '2019', '', 'Designed', 'Machine', 'Learning', 'model', 'predicts', 'human', 'activities', 'Walking', 'Walking', 'etc', 'using', 'LSTM', 'algorithm', 'achieving', 'accuracy', '9097', '', 'Language', 'Python', 'Libraries', 'Scikitlearn', 'Keras', 'LEADERSHIPAWARDS', 'Mentor', 'Accenture', 'June', '2018', 'Mentored', 'oversaw', 'team', '5', 'new', 'joiners', 'ensure', 'smooth', 'transition', 'team', 'average', 'rating', '48', '5', 'Alchemist', 'Accenture', 'March', '2019', 'Awarded', '1st', 'prize', 'best', 'work', 'efficiency', '500', 'employees'] ['Karthik', 'Ramanarayana', '2001', 'Eastern', 'Avenue', 'Baltimore', 'MD', '21231', 'Contact', 'No', '410', '2921151', 'Email', 'ID', 'karthikr2194', 'gmailcom', 'LinkedIn', 'https', 'wwwlinkedincominkarthikramanarayana77b4091b8', 'EDUCATION', 'University', 'Maryland', 'Baltimore', 'County', 'Baltimore', 'Maryland', 'Dec', '2021', 'Expected', 'Master', 'Professional', 'Studies', 'Data', 'Science', 'GPA', '374', 'Bangalore', 'Institute', 'Technology', 'Bangalore', 'India', 'May', '2016', 'Bachelor', 'Engineering', 'Electronics', 'Communication', 'Engineering', 'SKILLS', 'Programming', 'C', 'Python', 'SQL', 'PySpark', 'Database', 'MySQL', 'PostgreSQL', 'MongoDB', 'HBase', 'Data', 'Skills', 'Data', 'Visualization', 'Data', 'Modelling', 'Data', 'normalization', 'Machine', 'Learning', 'Data', 'Mining', 'Statistics', 'Big', 'Data', 'Hadoop', 'Spark', 'Hive', 'Kafka', 'Airflow', 'BI', 'Tools', 'Tableau', 'Power', 'BI', 'AWS', 'S3', 'Redshift', 'Glue', 'Athena', 'Redshift', 'Spectrum', 'QuickSight', 'Libraries', 'Numpy', 'Pandas', 'Spacy', 'NLTK', 'ScikitLearn', 'Keras', 'Tools', 'Software', 'Git', 'MS', 'Excel', 'MS', 'PowerPoint', 'MS', 'Word', 'SharePoint', 'Jupyter', 'Jira', 'WORK', 'EXPERIENCE', 'Data', 'Intern', 'Index', 'Analytics', 'LLC', 'Baltimore', 'MD', 'January', '2021', '', 'May', '2021', '', 'Designed', 'created', 'database', 'based', 'Star', 'Schema', 'dimensional', 'modelling', 'Employee', 'Skills', 'Matrix', 'data', '', 'Transformed', 'cleaned', 'raw', 'data', 'using', 'Python', 'create', 'fact', 'dimension', 'tables', '', 'Built', 'executive', 'level', 'Power', 'BI', 'Dashboard', 'visualize', 'BI', 'Reports', 'Employee', 'Skills', 'data', 'reducing', 'workload', '30', '', 'Led', 'managed', 'team', '3', 'following', 'Agile', 'methodology', 'using', 'Jira', 'tool', 'Junior', 'Data', 'Engineer', 'Accenture', 'Bangalore', 'India', 'July', '2018July', '2019', '', 'Implemented', 'ELT', 'Data', 'Pipeline', 'examine', 'user', 'behavior', 'music', 'streaming', 'client', 'company', '', 'Utilized', 'PySpark', 'improve', 'data', 'ingestion', 'processing', 'speed', '20', '', 'Ingested', 'data', 'versatile', 'data', 'sources', 'like', 'RDBMS', 'NOSQL', 'APIs', 'loaded', 'Data', 'Lake', 'central', 'repository', '', 'Developed', 'data', 'mappings', 'data', 'modelling', 'create', 'OLAP', 'databases', 'analytics', 'ensuring', 'robust', 'data', 'quality', 'Associate', 'Software', 'Engineer', 'Accenture', 'Bangalore', 'India', 'November', '2016June', '2018', '', 'Developed', 'implemented', 'ABAP', 'programs', 'customize', 'SAP', 'transactions', 'using', 'OOPS', 'concepts', '', 'Devised', 'redesigned', 'custom', 'Reports', 'Smart', 'forms', 'enhanced', 'accuracy', 'ABAP', 'jobs', '30', '', 'Identified', 'fixed', 'software', 'bugs', 'debugging', 'ABAP', 'programs', 'decreasing', 'software', 'downtime', '15', 'ACADEMIC', 'PROJECTS', 'Sentiment', 'Analysis', 'Billboard', 'Top', '100', 'Songs', 'August', 'October', '2020', '', 'Collaborated', 'team', '5', 'analyze', 'mindset', 'year', 'using', 'Natural', 'language', 'Processing', 'song', 'lyrics', '', 'Language', 'Python', 'Libraries', 'Pandas', 'Gensim', 'NLTK', 'Spacy', 'Movie', 'Recommendation', 'system', 'October', 'November', '2020', '', 'Recommended', 'new', 'movies', 'users', 'using', 'ALS', 'algorithm', 'root', 'mean', 'square', 'error', 'less', '09', '', 'Language', 'Python', 'Tools', 'Apache', 'Spark', 'Libraries', 'Pandas', 'Pyspark', 'Human', 'Activity', 'Recognition', 'February', '', 'March', '2019', '', 'Designed', 'Machine', 'Learning', 'model', 'predicts', 'human', 'activities', 'Walking', 'Walking', 'etc', 'using', 'LSTM', 'algorithm', 'achieving', 'accuracy', '9097', '', 'Language', 'Python', 'Libraries', 'Scikitlearn', 'Keras', 'LEADERSHIPAWARDS', 'Mentor', 'Accenture', 'June', '2018', 'Mentored', 'oversaw', 'team', '5', 'new', 'joiners', 'ensure', 'smooth', 'transition', 'team', 'average', 'rating', '48', '5', 'Alchemist', 'Accenture', 'March', '2019', 'Awarded', '1st', 'prize', 'best', 'work', 'efficiency', '500', 'employees']\n"
     ]
    }
   ],
   "source": [
    "print(words,simple_strings,res,res1,res2,res3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Indian Last names\n",
    ">Source: https://www.momjunction.com/articles/popular-indian-last-names-for-your-baby_00334734/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_last_names = [\"Acharya\", \"Agarwal\", \"Khatri\", \"Ahuja\", \"Anand\", \"Laghari\", \"Patel\",\n",
    "\n",
    "\"Reddy\", \"Bakshi\", \"Anthony\", \"Babu\", \"Arya\", \"Balakrishnan\", \"Banerjee\", \"Burman\", \"Bhatt\", \"Basu\", \"Bedi\", \"Varma\", \"Dara\", \"Dalal\", \"Chowdhury\",\n",
    "\"Chabra\", \"Chadha\", \"Chakrabarti\",\"Chawla\",\"Ahluwalia\", \"Amin\", \"Apte\", \"Datta\", \"Deol\", \"Deshpande\", \"Dewan\", \"Lal\", \"Kohli\", \"Mangal\", \"Malhotra\", \"Jha\",\n",
    "\"Joshi\",\"Kapadia\", \"Iyer\", \"Jain\", \"Khanna\", \"Grover\", \"Kaur\", \"Kashyap\", \"Gokhale\", \"Ghosh\", \"Garg\", \"Dhar\", \"Gandhi\", \"Ganguly\", \"Gupta\", \"Das\", \"Chopra\", \"Dhawan\",\n",
    "\"Dixit\", \"Dubey\", \"Haldar\", \"Kapoor\", \"Khurana\", \"Kulkarni\", \"Madan\", \"Bajwa\", \"Bhasin\", \"Chandra\", \"Chauhan\", \"Deshmukh\", \"Dayal\", \"Dhillon\", \"Goswami\", \"Goel\", \"Mallick\",\n",
    "\"Mahajan\", \"Kumar\", \"Mani\",  \"Gill\", \"Mannan\", \"Biswas\", \"Batra\", \"Bawa\", \"Mehta\", \"Mukherjee\", \"Saxena\", \"Zacharia\", \"Shah\", \"Ray\", \"Rao\", \"Purohit\", \"Parekh\", \"Thakur\", \"Singh\", \"Sharma\", \"Seth\", \"Sachdev\", \"Ranganathan\", \"Puri\", \"Pandey\", \"Naidu\", \"Modi\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of chinese last names\n",
    ">Source: \"https://mandarinhouse.com/100-common-chinese-family-names\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_last_names = [\"Li\", \"Wang\", \"Zhang\", \"Liu\", \"Chen\", \"Yang\", \"Zhao\", \"Huang\", \"Zhou\",\n",
    "\n",
    "\"Wu\", \"Xu\", \"Sun\", \"Hu\", \"Zhu\", \"Gao\", \"Lin\", \"He\", \"Guo\", \"Ma\", \"Luo\", \"Liang\",\n",
    "\n",
    "\"Song\", \"Zheng\", \"Xie\", \"Han\", \"Tang\", \"Feng\", \"Yu\", \"Dong\", \"Xiao\", \"Cheng\",\n",
    "\n",
    "\"Cao\", \"Yuan\", \"Deng\", \"Xu\", \"Fu\", \"Shen\", \"Zeng\", \"Peng\", \"Lu\", \"Su\", \"Lu\", \"Jiang\", \"Cai\", \"Jia\", \"Ding\", \"Wei\", \"Xue\", \"Ye\", \"Yan\", \n",
    "\n",
    "\"Yu\", \"Pan\", \"Du\", \"Dai\", \"Xia\", \"Zhong\", \"Wang\", \"Tian\", \"Ren\", \"Jiang\", \"Fan\", \"Fang\", \"Shi\", \"Yao\", \"Tan\", \"Sheng\", \"Zou\", \"Xiong\", \"Jin\", \"Lu\", \"Hao\", \"Kong\", \"Bai\", \"Cui\",\n",
    "\n",
    "\"Kang\", \"Mao\", \"Qio\", \"Qin\", \"Jiang\", \"Shu\", \"Shi\", \"Gu\", \"Hou\", \"Shao\", \"Meng\", \"Long\", \"Wan\", \"Duan\", \"Zhang\", \"Qian\", \"Tang\", \"Yin\", \"Li\", \"Yi\", \"Chang\", \"Wu\", \n",
    "    \n",
    "\"Qiao\", \"He\", \"Lao\", \"Gong\", \"Wen\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_last_names = [chinese_last_name.lower() for chinese_last_name in chinese_last_names]\n",
    "indian_last_names = [indian_last_name.lower() for indian_last_name in indian_last_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESERVED_WORDS = [\n",
    "    'school',\n",
    "    'college',\n",
    "    'univers',\n",
    "    'academy',\n",
    "    'faculty',\n",
    "    'institute',\n",
    "    'faculdades',\n",
    "    'Schola',\n",
    "    'schule',\n",
    "    'lise',\n",
    "    'lyceum',\n",
    "    'lycee',\n",
    "    'polytechnic',\n",
    "    'kolej',\n",
    "    'ünivers',\n",
    "    'okul',\n",
    "    'University'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(i):\n",
    "    ###Extract text from files\n",
    "    \"\"\"with pdfplumber.open(files1[i]) as pdf:\n",
    "        first_page = pdf.pages[0]\n",
    "        txt = first_page.extract_text()\"\"\"\n",
    "    txt = extract_text(files1[i], codec='utf-8')\n",
    "    #print(txt)\n",
    "    words = nltk.word_tokenize(txt) \n",
    "    return words,i,txt\n",
    "\n",
    "\n",
    "def preprocessing(i=0, person=[],education=[]):\n",
    "    ##Here i is for iterating over the files and doing the process for each file\n",
    "    words,i,txt = tokenize(i)\n",
    "    #print(txt)\n",
    "    ##removing stopwords and punctuations\n",
    "    simple_strings = [word for word in words if word not in stopwords if word not in string.punctuation]\n",
    "    res = [re.sub(r'[^\\w\\s]', '', word) for word in simple_strings]\n",
    "    res1 = [re.sub(r'^abc(.*?)=[A-Z0-9]+(.*)', r'\\1\\2', word) for word in res]\n",
    "    res2 = [str(res) for res in res1]\n",
    "    res3 = [re.sub(r'/^[A-Za-z]+$/', '', res) for res in res2]\n",
    "    \n",
    "    ##removing some ascii character\n",
    "    res3 = [res.replace(\"ï\",\"i\") if \"ï\" in res else res for res in res3]\n",
    "    \n",
    "    ##removing numbers\n",
    "    res3 = [re.sub('\\d', '', res) for res in res3]\n",
    "    \n",
    "    ##trying to remove acii characters\n",
    "    res3 = [res.encode('ascii',\"ignore\").decode() for res in res3]\n",
    "    \n",
    "    ##using the tagger object of StanfordNER for tagging the entities of the words \n",
    "    tagged = tagger.tag(res3)\n",
    "    \n",
    "    ## appending the names extracted from name_person\n",
    "    ##Since 2 files are of weird format ( 1 is image file converted into .pdf)\n",
    "    try:\n",
    "        person.append(name_person(tagged,words,res3))\n",
    "    except:\n",
    "        print(\"yes\")\n",
    "        person.append(files1[i])\n",
    "        pass\n",
    "    #tagged_list.append(tagged)\n",
    "    if i+1 < len(files1):\n",
    "        i+=1\n",
    "        preprocessing(i, person)\n",
    "    education.append(extract_education(txt))\n",
    "    return person, education\n",
    "\n",
    "def name_person(tagged, words,res3):\n",
    "    #tagged_list = preprocessing(0,[],[])\n",
    "    #print(tagged_list)\n",
    "    person = []\n",
    "    temp_person = []\n",
    "    \n",
    "    for k in range(10):\n",
    "        if res3[k].lower() in indian_last_names or res3[k].lower() in chinese_last_names:\n",
    "            j = k-1\n",
    "            return res3[j]+\"(Extracted using 1st approach)\"\n",
    "    for tuple_ele in tagged:\n",
    "        if \"PERSON\" in tuple_ele[1]:\n",
    "            temp_person.append(tuple_ele[0])\n",
    "    ## loop through the original words so we can extract from the first words and get the first PERSON\n",
    "    for word in words:\n",
    "        if word in temp_person:\n",
    "            return word\n",
    "\n",
    "def extract_education(txt):\n",
    "    edu=set()\n",
    "    for m in re.finditer(p,txt):\n",
    "        try:\n",
    "            if any(x in m.group(1) for x in RESERVED_WORDS):\n",
    "                edu.append(m.group(1))\n",
    "        except:\n",
    "            pass\n",
    "        for word in RESERVED_WORDS:\n",
    "            if word in m.group(2):\n",
    "                edu.add(m.group(2))\n",
    "    return edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Changed the approach of extracting names in this way:***\n",
    "- If your last name is in the resume in the top 10 names then your first name (the previous word will be returned)\n",
    "- Otherwise StanfordNER algorithm will be applied to extract names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "yes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Karthik',\n",
       "  'Robert',\n",
       "  'TIRTH(Extracted using 1st approach)',\n",
       "  'Akanksha',\n",
       "  'Mythri',\n",
       "  'Qizhe(Extracted using 1st approach)',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  None,\n",
       "  'Akash',\n",
       "  'Sharpe',\n",
       "  'Alexandra',\n",
       "  'Python',\n",
       "  'Wanting(Extracted using 1st approach)',\n",
       "  'Boston(Extracted using 1st approach)',\n",
       "  'Boston(Extracted using 1st approach)',\n",
       "  'Yuchen(Extracted using 1st approach)',\n",
       "  'JOHNSON',\n",
       "  'Indupriya',\n",
       "  'James',\n",
       "  'ANYA(Extracted using 1st approach)',\n",
       "  'Ryan',\n",
       "  'Mayank(Extracted using 1st approach)',\n",
       "  None,\n",
       "  'Noah',\n",
       "  'Python',\n",
       "  'Adam',\n",
       "  'Python',\n",
       "  'Jira',\n",
       "  'Akshay',\n",
       "  'Python',\n",
       "  'Nath(Extracted using 1st approach)',\n",
       "  'Amol',\n",
       "  'Yuchen(Extracted using 1st approach)',\n",
       "  'ANIRUDH(Extracted using 1st approach)',\n",
       "  'Middough',\n",
       "  'Antton',\n",
       "  'ANYA(Extracted using 1st approach)',\n",
       "  None,\n",
       "  'Django',\n",
       "  'BAIYU(Extracted using 1st approach)',\n",
       "  'Priyanka',\n",
       "  'Dunbar',\n",
       "  'Python',\n",
       "  'Swift',\n",
       "  'Andrew',\n",
       "  'C:\\\\Users\\\\rtd91\\\\Data\\\\resume_samples\\\\C01-21120201_Jiayue_Fei.pdf',\n",
       "  'Python',\n",
       "  'Carlos',\n",
       "  'Cassin',\n",
       "  'CHENGWEI(Extracted using 1st approach)',\n",
       "  'CHETNA(Extracted using 1st approach)',\n",
       "  'Mario',\n",
       "  'Dhwani(Extracted using 1st approach)',\n",
       "  'JOHNSON',\n",
       "  'Divya(Extracted using 1st approach)',\n",
       "  'Elijah',\n",
       "  'Evan',\n",
       "  'EVAN',\n",
       "  'Gali',\n",
       "  'Caldwell',\n",
       "  'Hamza',\n",
       "  'Indupriya',\n",
       "  'Jairo',\n",
       "  'James',\n",
       "  'Jialu(Extracted using 1st approach)',\n",
       "  'Jianbo(Extracted using 1st approach)',\n",
       "  'Jiehong(Extracted using 1st approach)',\n",
       "  'Jim(Extracted using 1st approach)',\n",
       "  None,\n",
       "  'JIATING(Extracted using 1st approach)',\n",
       "  'Python',\n",
       "  'Lejian(Extracted using 1st approach)',\n",
       "  'Boston(Extracted using 1st approach)',\n",
       "  'Manisha(Extracted using 1st approach)',\n",
       "  'MASEN',\n",
       "  'Matthew',\n",
       "  'Bayes',\n",
       "  'Mikhail',\n",
       "  'Pepys',\n",
       "  'Kaplan',\n",
       "  'Mona',\n",
       "  'Siddique',\n",
       "  None,\n",
       "  'Boston(Extracted using 1st approach)',\n",
       "  None,\n",
       "  'PRAVEEN(Extracted using 1st approach)',\n",
       "  None,\n",
       "  'Aditya(Extracted using 1st approach)',\n",
       "  'Ali',\n",
       "  'Django',\n",
       "  'Anqi(Extracted using 1st approach)',\n",
       "  None,\n",
       "  'Arunava(Extracted using 1st approach)',\n",
       "  'Python',\n",
       "  'Paul',\n",
       "  'Bala',\n",
       "  None,\n",
       "  'Chaeeun',\n",
       "  'Chantelle',\n",
       "  'CHITRANJAN(Extracted using 1st approach)',\n",
       "  'P',\n",
       "  'ETHAN',\n",
       "  'Python',\n",
       "  'Harshitha',\n",
       "  'Robert',\n",
       "  'Hemanth(Extracted using 1st approach)',\n",
       "  None,\n",
       "  'Vidyavardhini',\n",
       "  None,\n",
       "  'Ahmed',\n",
       "  'Kaleb',\n",
       "  'Maria',\n",
       "  'Katherine',\n",
       "  'KRUTI(Extracted using 1st approach)',\n",
       "  'Devendra(Extracted using 1st approach)',\n",
       "  'Python',\n",
       "  'Bayes',\n",
       "  'Naina(Extracted using 1st approach)',\n",
       "  'Nasir',\n",
       "  None,\n",
       "  'Navina(Extracted using 1st approach)',\n",
       "  'Rakshit',\n",
       "  'Jayshree',\n",
       "  'Rishitha',\n",
       "  'Rohin',\n",
       "  None,\n",
       "  'Monte',\n",
       "  'Hadoop',\n",
       "  'Python',\n",
       "  'Tesla',\n",
       "  'Tesla',\n",
       "  None,\n",
       "  'Siyu',\n",
       "  None,\n",
       "  'C:\\\\Users\\\\rtd91\\\\Data\\\\resume_samples\\\\Resume_Srinath_Narayanan.pdf',\n",
       "  'Python',\n",
       "  'Srushti(Extracted using 1st approach)',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Tableau',\n",
       "  'Tezeswi',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'WEICHEN(Extracted using 1st approach)',\n",
       "  'Yann',\n",
       "  'Glen',\n",
       "  'Yingkun(Extracted using 1st approach)',\n",
       "  'YING(Extracted using 1st approach)',\n",
       "  'Yutong(Extracted using 1st approach)',\n",
       "  'Richie',\n",
       "  'Ricky',\n",
       "  'Boston(Extracted using 1st approach)',\n",
       "  'Ruoshi(Extracted using 1st approach)',\n",
       "  'Rutvik(Extracted using 1st approach)',\n",
       "  'Ryan',\n",
       "  'Sahana',\n",
       "  'SAI(Extracted using 1st approach)',\n",
       "  'Sam(Extracted using 1st approach)',\n",
       "  'Senthil',\n",
       "  'Sharmista',\n",
       "  'Shian(Extracted using 1st approach)',\n",
       "  'Shreya',\n",
       "  None,\n",
       "  'H(Extracted using 1st approach)',\n",
       "  'Sushant',\n",
       "  'Boston(Extracted using 1st approach)',\n",
       "  'TZUYAO(Extracted using 1st approach)',\n",
       "  'UDAY',\n",
       "  None,\n",
       "  'VICTOR',\n",
       "  'Wenmo(Extracted using 1st approach)',\n",
       "  'Python',\n",
       "  'Oliver(Extracted using 1st approach)',\n",
       "  'Python',\n",
       "  None,\n",
       "  'Yiru',\n",
       "  'Zoe(Extracted using 1st approach)',\n",
       "  'Zhengyang',\n",
       "  'Zhuohan(Extracted using 1st approach)',\n",
       "  'Zixiao(Extracted using 1st approach)',\n",
       "  '(Extracted using 1st approach)'],\n",
       " [set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'Rutgers University'},\n",
       "  set(),\n",
       "  {'Awards: Phillips 66 SHIELD Scholar'},\n",
       "  set(),\n",
       "  {'Columbia University', 'University of Washington'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'KLE Technological University', 'New York University'},\n",
       "  {'Duke University',\n",
       "   'National Chung Cheng University(CCU)',\n",
       "   'National Taiwan University(NTU)'},\n",
       "  set(),\n",
       "  {'Savitribai Phule Pune University'},\n",
       "  set(),\n",
       "  set(),\n",
       "  {'The University of Texas at Dallas: - M.S.'},\n",
       "  set(),\n",
       "  {'GITAM University', 'ROWAN University'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'Jawaharlal Nehru Technological University', 'San Jose State University'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'Georgia State University'},\n",
       "  {'Jadavpur University'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'Data Analytics Bootcamp Certification: Johns Hopkins University'},\n",
       "  {'+ University of California'},\n",
       "  {'American University',\n",
       "   'DC Public School & American University',\n",
       "   'Soochow University'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'Assistant Business Analyst | University of Texas at Dallas'},\n",
       "  {'Michigan State University (MSU)'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'•  Bachelor’s in computer science from Jawaharlal Nehru Technological University',\n",
       "   '•  Master’s in computer science from Wright State University'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'University of Maryland'},\n",
       "  {'University of Maryland Baltimore County'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'Gujarat Technological University', 'Northeastern University'},\n",
       "  set(),\n",
       "  set(),\n",
       "  {'University of Central Missouri'},\n",
       "  set(),\n",
       "  {' University of Barishal',\n",
       "   'B.Sc. (Honors) in Mathematics   University of Dhaka',\n",
       "   'Ball State University (BSU)',\n",
       "   'Board Scholarship (undergraduate level',\n",
       "   'Bowling Green State University (BGSU)',\n",
       "   'M.S. in Applied Mathematics  University of Dhaka'},\n",
       "  set(),\n",
       "  {'University of Massachusetts Lowell', 'University of Mumbai'},\n",
       "  set(),\n",
       "  {'Graduate Excellence Scholar'},\n",
       "  set(),\n",
       "  set(),\n",
       "  {'University of South Florida'},\n",
       "  {'Howard University'},\n",
       "  set(),\n",
       "  {'Drexel University'},\n",
       "  set(),\n",
       "  {' University of Maryland  College Park', '●  Roberta Ma Scholarship'},\n",
       "  set(),\n",
       "  {'Anna University', 'Wayne State University'},\n",
       "  set(),\n",
       "  set(),\n",
       "  {'Johns Hopkins University'},\n",
       "  set(),\n",
       "  {'University of Maryland'},\n",
       "  set(),\n",
       "  {'                           January 2020 – May 2022   University of North Carolina at Charlotte',\n",
       "   'September 2014 - September 2019  Islamic Azad University'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'Gujarat Technological University'},\n",
       "  {'Purdue University',\n",
       "   'Research Assistant | Purdue University',\n",
       "   'Teaching Assistant | Purdue University'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'University of Houston'},\n",
       "  {'University of Nebraska'},\n",
       "  set(),\n",
       "  {'National University of Singapore- HPE',\n",
       "   '•  Northeastern University',\n",
       "   '•  REVA University'},\n",
       "  {'Cornell University', 'Sun Yat-sen University'},\n",
       "  {'Master of Science in Industrial Engineering (GPA 3.89/4.0) | Northeastern University'},\n",
       "  set(),\n",
       "  {'Columbia University'},\n",
       "  set(),\n",
       "  {'Aspiring dual-degree new grad looking for position where I can apply what I learned in university'},\n",
       "  {'⚫  Lehigh University',\n",
       "   '⚫  Tongji University',\n",
       "   '⚫  University of Michigan'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'Northeastern University', 'Visveswaraya Technological University'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'  Missouri University of Science and Technology',\n",
       "   'Jawaharlal Nehru Technological University'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'New York University', 'University of California Los Angeles'},\n",
       "  {'Anna University', 'The University of Texas at Dallas'},\n",
       "  set(),\n",
       "  {'Brandeis University | Waltham'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'University of Maryland',\n",
       "   'schools across 4 counties of California (Santa Clara'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'Cleveland State University'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'University of Southern California'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'University of Arkansas at Little Rock', 'University of Ilorin'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'University of Maryland'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'Northeastern University', 'Visveswaraya Technological University'},\n",
       "  set(),\n",
       "  {'University of California'},\n",
       "  {'Data Scientist/Research Assistant | Northeastern University',\n",
       "   'Graduate Teaching Assistant | Northeastern University'},\n",
       "  {'National University of Singapore- HPE',\n",
       "   '•  Northeastern University',\n",
       "   '•  REVA University'},\n",
       "  set(),\n",
       "  set(),\n",
       "  {'DePaul University', 'Northwestern University'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'University of Houston'},\n",
       "  set(),\n",
       "  {'Nirma University', 'The University of Texas at Dallas'},\n",
       "  set(),\n",
       "  {'University of Maryland'}])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 of the failed examples:\n",
    "- Here all the words including names are not recognized as \"PERSON\" and instead recognized as something else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('RACHAN', 'O'), ('VAMSI', 'O'), ('BHOOSHI', 'O'), ('Prospect', 'O'), ('Street', 'O'), ('APT', 'O'), ('N', 'O'), ('Stamford', 'LOCATION'), ('CT', 'O'), ('rachan_vamsibhooshi', 'O'), ('uconnedu', 'O'), ('LinkedIn', 'O'), ('Zoom', 'O'), ('GitHub', 'O'), ('SUMMARY', 'O'), ('Worked', 'O'), ('Graduate', 'O'), ('Research', 'O'), ('Assistant', 'O'), ('University', 'O'), ('Connecticut', 'O'), ('Eversource', 'O'), ('I', 'O'), ('supported', 'O'), ('research', 'O'), ('scheduling', 'O'), ('vehicle', 'O'), ('routing', 'O'), ('optimization', 'O'), ('prescriptive', 'O'), ('modeling', 'O'), ('Strategic', 'O'), ('innovative', 'O'), ('resultsdriven', 'O'), ('professional', 'O'), ('expertise', 'O'), ('implementing', 'O'), ('big', 'O'), ('data', 'O'), ('analytics', 'O'), ('strong', 'O'), ('leadership', 'O'), ('communication', 'O'), ('skills', 'O'), ('EDUCATION', 'O'), ('Master', 'O'), ('Science', 'O'), ('Business', 'O'), ('Analytics', 'O'), ('Project', 'O'), ('Management', 'O'), ('December', 'O'), ('UNIVERSITY', 'O'), ('OF', 'O'), ('CONNECTICUT', 'O'), ('GPA', 'O'), ('years', 'O'), ('work', 'O'), ('authorization', 'O'), ('STEMextension', 'O'), ('OPT', 'O'), ('Bachelor', 'O'), ('Technology', 'O'), ('Mechanical', 'O'), ('Engineering', 'O'), ('May', 'O'), ('NATIONAL', 'O'), ('INSTITUTE', 'O'), ('OF', 'O'), ('TECHNOLOGY', 'O'), ('ROURKELA', 'O'), ('SKILLS', 'O'), ('Programming', 'O'), ('Language', 'O'), ('Tools', 'O'), ('Python', 'O'), ('R', 'O'), ('Google', 'ORGANIZATION'), ('Analytics', 'ORGANIZATION'), ('GitHub', 'O'), ('Docker', 'O'), ('Kubernetes', 'O'), ('Hadoop', 'O'), ('SQL', 'O'), ('Apache', 'O'), ('Airflow', 'O'), ('SAS', 'O'), ('programming', 'O'), ('JMP', 'ORGANIZATION'), ('Alteryx', 'ORGANIZATION'), ('Tableau', 'ORGANIZATION'), ('Power', 'ORGANIZATION'), ('BI', 'ORGANIZATION'), ('Apache', 'ORGANIZATION'), ('Spark', 'ORGANIZATION'), ('Snowflake', 'ORGANIZATION'), ('MS', 'ORGANIZATION'), ('Excel', 'ORGANIZATION'), ('VLOOKUP', 'ORGANIZATION'), ('Pivot', 'ORGANIZATION'), ('Tables', 'ORGANIZATION'), ('MS', 'ORGANIZATION'), ('Office', 'ORGANIZATION'), ('MS', 'ORGANIZATION'), ('Access', 'ORGANIZATION'), ('MS', 'ORGANIZATION'), ('Visio', 'ORGANIZATION'), ('HTML', 'O'), ('Google', 'ORGANIZATION'), ('Cloud', 'O'), ('Platform', 'O'), ('Tools', 'O'), ('Kubernetes', 'O'), ('Engine', 'O'), ('Compute', 'O'), ('Engine', 'O'), ('Big', 'O'), ('Query', 'O'), ('Cloud', 'O'), ('Pub', 'O'), ('Sub', 'ORGANIZATION'), ('Cloud', 'ORGANIZATION'), ('Data', 'ORGANIZATION'), ('Flow', 'ORGANIZATION'), ('Cloud', 'ORGANIZATION'), ('Data', 'ORGANIZATION'), ('Fusion', 'ORGANIZATION'), ('Cloud', 'O'), ('Composer', 'O'), ('Cloud', 'O'), ('Functions', 'O'), ('Stack', 'O'), ('driver', 'O'), ('Google', 'ORGANIZATION'), ('APIs', 'O'), ('Statistical', 'O'), ('ML', 'O'), ('Techniques', 'O'), ('Managerial', 'O'), ('Decision', 'O'), ('Modeling', 'O'), ('Prescriptive', 'O'), ('Analysis', 'O'), ('Descriptive', 'O'), ('Analysis', 'O'), ('Supervised', 'O'), ('Unsupervised', 'O'), ('Machine', 'O'), ('Learning', 'O'), ('Regression', 'O'), ('Classification', 'O'), ('Decision', 'O'), ('Trees', 'O'), ('Random', 'O'), ('Forest', 'O'), ('Principal', 'O'), ('Component', 'O'), ('Analysis', 'O'), ('Clustering', 'O'), ('Text', 'O'), ('Analysis', 'O'), ('Pivot', 'O'), ('tables', 'O'), ('Time', 'ORGANIZATION'), ('Series', 'ORGANIZATION'), ('Forecasting', 'ORGANIZATION'), ('Business', 'ORGANIZATION'), ('Intelligence', 'ORGANIZATION'), ('Convolution', 'ORGANIZATION'), ('Neural', 'ORGANIZATION'), ('Networks', 'ORGANIZATION'), ('Recurrent', 'ORGANIZATION'), ('Neural', 'ORGANIZATION'), ('Network', 'ORGANIZATION'), ('LSTM', 'ORGANIZATION'), ('Modeling', 'ORGANIZATION'), ('Autoencoders', 'ORGANIZATION'), ('AB', 'ORGANIZATION'), ('Testing', 'ORGANIZATION'), ('Association', 'ORGANIZATION'), ('Rule', 'ORGANIZATION'), ('Mining', 'ORGANIZATION'), ('Web', 'ORGANIZATION'), ('Scraping', 'ORGANIZATION'), ('Version', 'ORGANIZATION'), ('Control', 'ORGANIZATION'), ('ETL', 'ORGANIZATION'), ('ELT', 'ORGANIZATION'), ('processing', 'O'), ('parallel', 'O'), ('processing', 'O'), ('data', 'O'), ('pipelines', 'O'), ('deployment', 'O'), ('Route', 'O'), ('optimization', 'O'), ('work', 'O'), ('scheduling', 'O'), ('EXPERIENCE', 'O'), ('UNIVERSITY', 'O'), ('OF', 'O'), ('CONNECTICUT', 'O'), ('Stamford', 'LOCATION'), ('CT', 'O'), ('June', 'O'), ('Present', 'O'), ('Graduate', 'O'), ('Research', 'O'), ('Assistant', 'O'), ('Develop', 'O'), ('implement', 'O'), ('code', 'O'), ('TSP', 'O'), ('Work', 'O'), ('Scheduling', 'O'), ('Problems', 'O'), ('Python', 'PERSON'), ('using', 'O'), ('optimization', 'O'), ('Design', 'O'), ('test', 'O'), ('algorithms', 'O'), ('strategies', 'O'), ('decrease', 'O'), ('costs', 'O'), ('million', 'O'), ('dollars', 'O'), ('Eversource', 'O'), ('USA', 'LOCATION'), ('decrease', 'O'), ('total', 'O'), ('restoration', 'O'), ('time', 'O'), ('days', 'O'), ('increase', 'O'), ('work', 'O'), ('efficiency', 'O'), ('using', 'O'), ('KPIs', 'O'), ('OTHER', 'O'), ('EXPERIENCES', 'O'), ('CONVERGENCE', 'O'), ('INC', 'O'), ('Norwalk', 'LOCATION'), ('CT', 'O'), ('May', 'O'), ('July', 'O'), ('Analyst', 'O'), ('Intern', 'O'), ('Designed', 'O'), ('Created', 'O'), ('Manager', 'O'), ('Affiliation', 'O'), ('model', 'O'), ('ingestion', 'O'), ('process', 'O'), ('Advisors', 'O'), ('Big', 'O'), ('Query', 'O'), ('Snowflake', 'O'), ('Schema', 'O'), ('Developed', 'O'), ('performed', 'O'), ('unit', 'O'), ('testing', 'O'), ('ELT', 'O'), ('data', 'O'), ('pipelines', 'O'), ('improve', 'O'), ('risk', 'O'), ('identification', 'O'), ('UNIVERSITY', 'O'), ('OF', 'O'), ('CONNECTICUT', 'O'), ('Stamford', 'LOCATION'), ('CT', 'O'), ('January', 'O'), ('Present', 'O'), ('Teaching', 'O'), ('Assistant', 'O'), ('Business', 'O'), ('Decision', 'O'), ('Modeling', 'O'), ('Guide', 'O'), ('students', 'O'), ('understanding', 'O'), ('concepts', 'O'), ('Managerial', 'O'), ('Decision', 'O'), ('Modeling', 'O'), ('Develop', 'O'), ('code', 'O'), ('real', 'O'), ('world', 'O'), ('problems', 'O'), ('Operational', 'O'), ('Research', 'O'), ('leveraging', 'O'), ('environmental', 'O'), ('factors', 'O'), ('ANALYTICS', 'O'), ('ACADEMIC', 'O'), ('PROJECTS', 'O'), ('Realtime', 'O'), ('Stock', 'O'), ('Market', 'O'), ('Prediction', 'O'), ('voice', 'O'), ('input', 'O'), ('Python', 'O'), ('NLTK', 'O'), ('Google', 'ORGANIZATION'), ('Speech', 'O'), ('Text', 'O'), ('API', 'O'), ('pandas', 'O'), ('ScikitLearn', 'O'), ('TensorFlow', 'O'), ('Google', 'ORGANIZATION'), ('Natural', 'O'), ('Language', 'O'), ('Processing', 'O'), ('API', 'O'), ('Emotion', 'O'), ('Recognition', 'O'), ('Project', 'O'), ('accuracy', 'O'), ('improve', 'O'), ('productivity', 'O'), ('health', 'O'), ('work', 'O'), ('Python', 'O'), ('Sentiment', 'O'), ('Analysis', 'O'), ('Deep', 'O'), ('Learning', 'O'), ('Model', 'O'), ('TensorFlow', 'O'), ('Serving', 'O'), ('TensorFlow', 'O'), ('Python', 'O'), ('Docker', 'O'), ('Tweet', 'O'), ('Classification', 'O'), ('Model', 'O'), ('predicting', 'O'), ('tweets', 'O'), ('Messi', 'PERSON'), ('Ronaldo', 'PERSON'), ('fans', 'O'), ('TensorFlow', 'O'), ('Python', 'O'), ('Travel', 'O'), ('Optimization', 'O'), ('using', 'O'), ('ORTools', 'O'), ('different', 'O'), ('route', 'O'), ('strategies', 'O'), ('travel', 'O'), ('parameters', 'O'), ('Python', 'O'), ('Market', 'O'), ('Basket', 'O'), ('Analysis', 'O'), ('Gas', 'O'), ('prices', 'O'), ('CO', 'O'), ('levels', 'O'), ('COVID', 'O'), ('cases', 'O'), ('decrease', 'O'), ('travel', 'O'), ('costs', 'O'), ('R', 'O')]\n",
      "Python\n"
     ]
    }
   ],
   "source": [
    "#txt = extract_text(files1[8], codec='utf-8')\n",
    "words = nltk.word_tokenize(txt)\n",
    "simple_strings = [word for word in words if word not in stopwords if word not in string.punctuation]\n",
    "res = [re.sub(r'[^\\w\\s]', '', word) for word in simple_strings]\n",
    "res1 = [re.sub(r'^abc(.*?)=[A-Z0-9]+(.*)', r'\\1\\2', word) for word in res]\n",
    "res2 = [str(res) for res in res1]\n",
    "res3 = [re.sub(r'/^[A-Za-z]+$/', '', res) for res in res2]\n",
    "\n",
    "##removing some ascii character\n",
    "res3 = [res.replace(\"ï\",\"i\") if \"ï\" in res else res for res in res3]\n",
    "\n",
    "##removing numbers\n",
    "res3 = [re.sub('\\d', '', res) for res in res3]\n",
    "\n",
    "##trying to remove acii characters\n",
    "res3 = [res.encode('ascii',\"ignore\").decode() for res in res3]\n",
    "\n",
    "##using the tagger object of StanfordNER for tagging the entities of the words \n",
    "tagged = tagger.tag(res3)\n",
    "print(tagged)\n",
    "## appending the names extracted from name_person\n",
    "print(name_person(tagged,words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
