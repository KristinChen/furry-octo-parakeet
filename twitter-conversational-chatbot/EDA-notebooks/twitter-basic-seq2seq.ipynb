{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "39717eda-bc31-4143-a87f-bac4eea63678",
    "_uuid": "e30b174032d05dd0048b02ca268f3b31cf5b183e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library versions:\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLibrary versions:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeras\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "print('Library versions:')\n",
    "\n",
    "import keras\n",
    "print(f'keras:{keras.__version__}')\n",
    "import pandas as pd\n",
    "print(f'pandas:{pd.__version__}')\n",
    "import sklearn\n",
    "print(f'sklearn:{sklearn.__version__}')\n",
    "import nltk\n",
    "print(f'nltk:{nltk.__version__}')\n",
    "import numpy as np\n",
    "print(f'numpy:{np.__version__}')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('punkt')\n",
    "import demoji\n",
    "import pickle\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import casual_tokenize\n",
    "import tensorflow as tf\n",
    "print(f'tensofrlow:{tf.__version__}')\n",
    "\n",
    "import os\n",
    "os.getcwd()\n",
    "\n",
    "demoji.__version__\n",
    "with open(r'./Emoji_Dict.p', 'rb') as fp:\n",
    "    Emoji_Dict = pickle.load(fp)\n",
    "    Emoji_Dict = {v: k for k, v in Emoji_Dict.items()}\n",
    "    \n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensofrlow:2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(f'tensofrlow:{tf.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm.notebook as tqdm # Special jupyter notebook progress bar üí´\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\JiatingChen\\\\Documents\\\\nlp-coe\\\\twitter-conversational-chatbot\\\\EDA-notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "24fb3871-ea0e-4b9e-b21c-ed76ccefc823",
    "_uuid": "ec0199c0dff22aeed45b9dbe1e7bf659e9449fe9"
   },
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "3217b16f-bf7c-4fed-bbea-d74e09a537e4",
    "_uuid": "6509f5443163b0d11f1a003bb8a28b79a340f192"
   },
   "outputs": [],
   "source": [
    "# 8192 - large enough for demonstration, larger values make network training slower\n",
    "MAX_VOCAB_SIZE = 2**13\n",
    "# seq2seq generally relies on fixed length message vectors - longer messages provide more info\n",
    "# but result in slower training and larger networks\n",
    "MAX_MESSAGE_LEN = 30  \n",
    "# Embedding size for words - gives a trade off between expressivity of words and network size\n",
    "EMBEDDING_SIZE = 100\n",
    "# Embedding size for whole messages, same trade off as word embeddings\n",
    "CONTEXT_SIZE = 100\n",
    "# Larger batch sizes generally reach the average response faster, but small batch sizes are\n",
    "# required for the model to learn nuanced responses.  Also, GPU memory limits max batch size.\n",
    "BATCH_SIZE = 4\n",
    "# Helps regularize network and prevent overfitting.\n",
    "DROPOUT = 0.2\n",
    "# High learning rate helps model reach average response faster, but can make it hard to \n",
    "# converge on nuanced responses\n",
    "LEARNING_RATE=0.005\n",
    "\n",
    "# Tokens needed for seq2seq\n",
    "UNK = 0  # words that aren't found in the vocab\n",
    "PAD = 1  # after message has finished, this fills all remaining vector positions\n",
    "START = 2  # provided to the model at position 0 for every response predicted\n",
    "\n",
    "# Implementaiton detail for allowing this to be run in Kaggle's notebook hardware\n",
    "SUB_BATCH_SIZE = 1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ea67c840-2d02-45df-be0b-ec5746e72028",
    "_uuid": "9f99990233daf26e624d6e0a735b8a3559eb54c9"
   },
   "source": [
    "## Data Prep\n",
    "Here, we'll prepare the data for training our seq2seq model, including:\n",
    "\n",
    "- Replace screen names with `@__sn__` token to show model the commonality between them\n",
    "- Build a vocab to turn tokens into integers suitable for our seq2seq model\n",
    "- Tokenize input and target text into fixed size vectors\n",
    "- Partition our dataset into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7e83096b-f411-494a-962b-80a76122e674",
    "_uuid": "8989bdc2a930380aa52af0ef6a296906d313715c"
   },
   "source": [
    "### Data Loading and Reshaping\n",
    "Pulled from [this kernel](https://www.kaggle.com/soaxelbrooke/first-inbound-and-response-tweets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 787346 first inbound messages.\n",
      "Found 875292 responses.\n",
      "Found 794299 responses from companies.\n",
      "Tweets Preview:\n",
      "        tweet_id_x author_id_x  inbound_x                    created_at_x  \\\n",
      "0                8      115712       True  Tue Oct 31 21:45:10 +0000 2017   \n",
      "1                8      115712       True  Tue Oct 31 21:45:10 +0000 2017   \n",
      "2                8      115712       True  Tue Oct 31 21:45:10 +0000 2017   \n",
      "3               18      115713       True  Tue Oct 31 19:56:01 +0000 2017   \n",
      "4               20      115715       True  Tue Oct 31 22:03:34 +0000 2017   \n",
      "...            ...         ...        ...                             ...   \n",
      "875287     2987942      823867       True  Wed Nov 22 07:30:39 +0000 2017   \n",
      "875288     2987944      823868       True  Wed Nov 22 07:43:36 +0000 2017   \n",
      "875289     2987946      524544       True  Wed Nov 22 08:25:48 +0000 2017   \n",
      "875290     2987948      823869       True  Wed Nov 22 08:35:16 +0000 2017   \n",
      "875291     2987950      823870       True  Tue Nov 21 22:01:04 +0000 2017   \n",
      "\n",
      "                                                   text_x response_tweet_id_x  \\\n",
      "0               @sprintcare is the worst customer service              9,6,10   \n",
      "1               @sprintcare is the worst customer service              9,6,10   \n",
      "2               @sprintcare is the worst customer service              9,6,10   \n",
      "3       @115714 y‚Äôall lie about your ‚Äúgreat‚Äù connectio...                  17   \n",
      "4       @115714 whenever I contact customer support, t...                  19   \n",
      "...                                                   ...                 ...   \n",
      "875287  Hai @AirAsiaSupport #asking how many days need...             2987941   \n",
      "875288  @AirAsiaSupport \\n\\nI am unable to do web chec...             2987943   \n",
      "875289  @VirginTrains Hope you are well? Does the 9.30...             2987945   \n",
      "875290  @115714 wtf!? I‚Äôve been having really shitty s...             2987947   \n",
      "875291  @AldiUK  warm sloe gin mince pies with ice cre...     2987951,2987949   \n",
      "\n",
      "        in_response_to_tweet_id_x  tweet_id_y     author_id_y  inbound_y  \\\n",
      "0                             NaN           6      sprintcare      False   \n",
      "1                             NaN           9      sprintcare      False   \n",
      "2                             NaN          10      sprintcare      False   \n",
      "3                             NaN          17      sprintcare      False   \n",
      "4                             NaN          19      sprintcare      False   \n",
      "...                           ...         ...             ...        ...   \n",
      "875287                        NaN     2987941  AirAsiaSupport      False   \n",
      "875288                        NaN     2987943  AirAsiaSupport      False   \n",
      "875289                        NaN     2987945    VirginTrains      False   \n",
      "875290                        NaN     2987947      sprintcare      False   \n",
      "875291                        NaN     2987949          AldiUK      False   \n",
      "\n",
      "                          created_at_y  \\\n",
      "0       Tue Oct 31 21:46:24 +0000 2017   \n",
      "1       Tue Oct 31 21:46:14 +0000 2017   \n",
      "2       Tue Oct 31 21:45:59 +0000 2017   \n",
      "3       Tue Oct 31 19:59:13 +0000 2017   \n",
      "4       Tue Oct 31 22:10:10 +0000 2017   \n",
      "...                                ...   \n",
      "875287  Wed Nov 22 07:55:05 +0000 2017   \n",
      "875288  Wed Nov 22 07:54:57 +0000 2017   \n",
      "875289  Wed Nov 22 08:27:34 +0000 2017   \n",
      "875290  Wed Nov 22 08:43:51 +0000 2017   \n",
      "875291  Wed Nov 22 08:31:24 +0000 2017   \n",
      "\n",
      "                                                   text_y response_tweet_id_y  \\\n",
      "0       @115712 Can you please send us a private messa...                 5,7   \n",
      "1       @115712 I would love the chance to review the ...                 NaN   \n",
      "2       @115712 Hello! We never like our customers to ...                 NaN   \n",
      "3       @115713 H there! We'd definitely like to work ...                  16   \n",
      "4       @115715 Please send me a private message so th...                 NaN   \n",
      "...                                                   ...                 ...   \n",
      "875287     @823867 we have replied you via DM.Thanks-Emir                 NaN   \n",
      "875288  @823868 Sorry but kindly try to clear browser,...                 NaN   \n",
      "875289  @524544 That's a Peak service. The 09:56 is th...                 NaN   \n",
      "875290  @823869 Hey, we'd be happy to look into this f...                 NaN   \n",
      "875291  @823870 Sounds delicious, Sarah! üòã https://t.c...                 NaN   \n",
      "\n",
      "        in_response_to_tweet_id_y  \n",
      "0                             8.0  \n",
      "1                             8.0  \n",
      "2                             8.0  \n",
      "3                            18.0  \n",
      "4                            20.0  \n",
      "...                           ...  \n",
      "875287                  2987942.0  \n",
      "875288                  2987944.0  \n",
      "875289                  2987946.0  \n",
      "875290                  2987948.0  \n",
      "875291                  2987950.0  \n",
      "\n",
      "[794299 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" A kernel posted on Kaggle that shows how to pull just the first consumer request and\n",
    "    company response from the dataset.\n",
    "\"\"\"\n",
    "\n",
    "tweets = pd.read_csv('../data/twcs/twcs.csv')\n",
    "\n",
    "\n",
    "# Pick only inbound tweets that aren't in reply to anything...\n",
    "first_inbound = tweets[pd.isnull(tweets.in_response_to_tweet_id) & tweets.inbound]\n",
    "print('Found {} first inbound messages.'.format(len(first_inbound)))\n",
    "\n",
    "# Merge in all tweets in response\n",
    "inbounds_and_outbounds = pd.merge(first_inbound, tweets, left_on='tweet_id', \n",
    "                                  right_on='in_response_to_tweet_id')\n",
    "print(\"Found {} responses.\".format(len(inbounds_and_outbounds)))\n",
    "\n",
    "# Filter out cases where reply tweet isn't from company\n",
    "inbounds_and_outbounds = inbounds_and_outbounds[inbounds_and_outbounds.inbound_y ^ True]\n",
    "\n",
    "# Et voila!\n",
    "print(\"Found {} responses from companies.\".format(len(inbounds_and_outbounds)))\n",
    "print(\"Tweets Preview:\")\n",
    "print(inbounds_and_outbounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   author_id  inbound                      created_at  \\\n",
       "0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @115712 I understand. I would like to assist y...                 2   \n",
       "1      @sprintcare and how do you propose we do that               NaN   \n",
       "2  @sprintcare I have sent several private messag...                 1   \n",
       "3  @115712 Please send us a Private Message so th...                 3   \n",
       "4                                 @sprintcare I did.                 4   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      3.0  \n",
       "1                      1.0  \n",
       "2                      4.0  \n",
       "3                      5.0  \n",
       "4                      6.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head() \n",
    "#inbound: message from others (response_tweet_id); outbound: message sent by the tweet_id (in_response_to_tweet_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "c9f2bbcb-e843-42d9-81ec-70be9465c4a8",
    "_uuid": "0c3d1708c29764aceb980a93bd9ac61fdf852a22",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 12.5 s\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweets = pd.read_csv('../data/twcs/twcs.csv')\n",
    "\n",
    "first_inbound = tweets[pd.isnull(tweets.in_response_to_tweet_id) & tweets.inbound]\n",
    "\n",
    "inbounds_and_outbounds = pd.merge(first_inbound, tweets, left_on='tweet_id', \n",
    "                                  right_on='in_response_to_tweet_id').sample(frac=1)\n",
    "\n",
    "# Filter to only outbound replies (from companies)\n",
    "inbounds_and_outbounds = inbounds_and_outbounds[inbounds_and_outbounds.inbound_y ^ True]\n",
    "\n",
    "#tqdm().pandas()  # Enable tracking of progress in dataframe `apply` calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9664b5fc42495286bcfa3108c176d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "1510aa86-71ce-41b6-bda9-6bec1206836b",
    "_uuid": "67186b1ace1e3fff0fed9ec9fe6fd0c59f009a5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (794299, 14)\n"
     ]
    }
   ],
   "source": [
    "print(f'Data shape: {inbounds_and_outbounds.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a0afc1aa-a34f-4ea5-b34e-2fb21b5da62e",
    "_uuid": "2478590bbc0924cc8e8dd127ac4fea8019f8b3f3"
   },
   "source": [
    "### Tokenizing and Vocab Build\n",
    "\n",
    "We'll use NLTK's `casual_tokenize`, which handles a lot of corner cases found in social media data (\"casual\" text data) along with scitkit learn's `CountVectorizer`.  We won't use the actual `CountVectorizer`, just use it as a convenient vocabulary builder, which we'll apply with functions that turn text into \"word indexes\" - integers that represent each word - and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "cab88942-373b-42fa-ac15-f341b19ced6f",
    "_uuid": "eccc4fdc8c0770ccb650c2fea30d7c4c5644ee4b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id_x</th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>inbound_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>response_tweet_id_x</th>\n",
       "      <th>in_response_to_tweet_id_x</th>\n",
       "      <th>tweet_id_y</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>inbound_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "      <th>response_tweet_id_y</th>\n",
       "      <th>in_response_to_tweet_id_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108568</th>\n",
       "      <td>416001</td>\n",
       "      <td>214212</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 10 02:15:29 +0000 2017</td>\n",
       "      <td>@ChipotleTweets my food fell out my bag...and ...</td>\n",
       "      <td>416000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>416000</td>\n",
       "      <td>ChipotleTweets</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 10 02:24:00 +0000 2017</td>\n",
       "      <td>@214212 Oh no. This is the saddest picture. Pl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>416001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277961</th>\n",
       "      <td>1020191</td>\n",
       "      <td>361403</td>\n",
       "      <td>True</td>\n",
       "      <td>Sat Nov 25 17:06:12 +0000 2017</td>\n",
       "      <td>#weak @115817 #noshow #iphone Delivery after w...</td>\n",
       "      <td>1020190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1020190</td>\n",
       "      <td>UPSHelp</td>\n",
       "      <td>False</td>\n",
       "      <td>Sat Nov 25 17:17:30 +0000 2017</td>\n",
       "      <td>@361403 Please DM us your tracking, delivery a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1020191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513149</th>\n",
       "      <td>1830526</td>\n",
       "      <td>523292</td>\n",
       "      <td>True</td>\n",
       "      <td>Sun Oct 29 00:56:52 +0000 2017</td>\n",
       "      <td>Really wanted to preorder the IphoneX but with...</td>\n",
       "      <td>1830524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1830524</td>\n",
       "      <td>TMobileHelp</td>\n",
       "      <td>False</td>\n",
       "      <td>Sun Oct 29 01:00:51 +0000 2017</td>\n",
       "      <td>@523292 Down payments on phones depends on eac...</td>\n",
       "      <td>1830525</td>\n",
       "      <td>1830526.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160768</th>\n",
       "      <td>599902</td>\n",
       "      <td>262329</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Nov 29 14:30:01 +0000 2017</td>\n",
       "      <td>@TfL please could you get back to me about thi...</td>\n",
       "      <td>599901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>599901</td>\n",
       "      <td>TfL</td>\n",
       "      <td>False</td>\n",
       "      <td>Sun Dec 03 19:10:20 +0000 2017</td>\n",
       "      <td>@262329 Hi Sam\\nSorry for the late reply \\nPle...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>599902.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159452</th>\n",
       "      <td>595603</td>\n",
       "      <td>261132</td>\n",
       "      <td>True</td>\n",
       "      <td>Sun Dec 03 12:33:35 +0000 2017</td>\n",
       "      <td>@hpsupport [How do I add my email accounts? It...</td>\n",
       "      <td>595602,595604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>595602</td>\n",
       "      <td>HPSupport</td>\n",
       "      <td>False</td>\n",
       "      <td>Sun Dec 03 18:39:19 +0000 2017</td>\n",
       "      <td>@261132 Send us a direct message by clicking o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>595603.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tweet_id_x author_id_x  inbound_x                    created_at_x  \\\n",
       "108568      416001      214212       True  Tue Oct 10 02:15:29 +0000 2017   \n",
       "277961     1020191      361403       True  Sat Nov 25 17:06:12 +0000 2017   \n",
       "513149     1830526      523292       True  Sun Oct 29 00:56:52 +0000 2017   \n",
       "160768      599902      262329       True  Wed Nov 29 14:30:01 +0000 2017   \n",
       "159452      595603      261132       True  Sun Dec 03 12:33:35 +0000 2017   \n",
       "\n",
       "                                                   text_x response_tweet_id_x  \\\n",
       "108568  @ChipotleTweets my food fell out my bag...and ...              416000   \n",
       "277961  #weak @115817 #noshow #iphone Delivery after w...             1020190   \n",
       "513149  Really wanted to preorder the IphoneX but with...             1830524   \n",
       "160768  @TfL please could you get back to me about thi...              599901   \n",
       "159452  @hpsupport [How do I add my email accounts? It...       595602,595604   \n",
       "\n",
       "        in_response_to_tweet_id_x  tweet_id_y     author_id_y  inbound_y  \\\n",
       "108568                        NaN      416000  ChipotleTweets      False   \n",
       "277961                        NaN     1020190         UPSHelp      False   \n",
       "513149                        NaN     1830524     TMobileHelp      False   \n",
       "160768                        NaN      599901             TfL      False   \n",
       "159452                        NaN      595602       HPSupport      False   \n",
       "\n",
       "                          created_at_y  \\\n",
       "108568  Tue Oct 10 02:24:00 +0000 2017   \n",
       "277961  Sat Nov 25 17:17:30 +0000 2017   \n",
       "513149  Sun Oct 29 01:00:51 +0000 2017   \n",
       "160768  Sun Dec 03 19:10:20 +0000 2017   \n",
       "159452  Sun Dec 03 18:39:19 +0000 2017   \n",
       "\n",
       "                                                   text_y response_tweet_id_y  \\\n",
       "108568  @214212 Oh no. This is the saddest picture. Pl...                 NaN   \n",
       "277961  @361403 Please DM us your tracking, delivery a...                 NaN   \n",
       "513149  @523292 Down payments on phones depends on eac...             1830525   \n",
       "160768  @262329 Hi Sam\\nSorry for the late reply \\nPle...                 NaN   \n",
       "159452  @261132 Send us a direct message by clicking o...                 NaN   \n",
       "\n",
       "        in_response_to_tweet_id_y  \n",
       "108568                   416001.0  \n",
       "277961                  1020191.0  \n",
       "513149                  1830526.0  \n",
       "160768                   599902.0  \n",
       "159452                   595603.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbounds_and_outbounds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 794299 entries, 108568 to 245074\n",
      "Data columns (total 14 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   tweet_id_x                 794299 non-null  int64  \n",
      " 1   author_id_x                794299 non-null  object \n",
      " 2   inbound_x                  794299 non-null  bool   \n",
      " 3   created_at_x               794299 non-null  object \n",
      " 4   text_x                     794299 non-null  object \n",
      " 5   response_tweet_id_x        794299 non-null  object \n",
      " 6   in_response_to_tweet_id_x  0 non-null       float64\n",
      " 7   tweet_id_y                 794299 non-null  int64  \n",
      " 8   author_id_y                794299 non-null  object \n",
      " 9   inbound_y                  794299 non-null  bool   \n",
      " 10  created_at_y               794299 non-null  object \n",
      " 11  text_y                     794299 non-null  object \n",
      " 12  response_tweet_id_y        263771 non-null  object \n",
      " 13  in_response_to_tweet_id_y  794299 non-null  float64\n",
      "dtypes: bool(2), float64(2), int64(2), object(8)\n",
      "memory usage: 80.3+ MB\n"
     ]
    }
   ],
   "source": [
    "inbounds_and_outbounds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AmazonHelp         0.106556\n",
       "AppleSupport       0.093960\n",
       "Uber_Support       0.050395\n",
       "Delta              0.035862\n",
       "SpotifyCares       0.033917\n",
       "Tesco              0.031332\n",
       "AmericanAir        0.030852\n",
       "comcastcares       0.030015\n",
       "SouthwestAir       0.026421\n",
       "TMobileHelp        0.025261\n",
       "British_Airways    0.024690\n",
       "Ask_Spectrum       0.021742\n",
       "VirginTrains       0.018075\n",
       "UPSHelp            0.017994\n",
       "hulu_support       0.017870\n",
       "ChipotleTweets     0.017441\n",
       "sprintcare         0.015925\n",
       "XboxSupport        0.015748\n",
       "AskPlayStation     0.014349\n",
       "sainsburys         0.013550\n",
       "Name: author_id_y, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbounds_and_outbounds.author_id_y.value_counts(normalize = True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "askvisa            0.000721\n",
       "ask_progressive    0.000658\n",
       "GooglePlayMusic    0.000643\n",
       "YahooCare          0.000640\n",
       "USCellularCares    0.000628\n",
       "asksalesforce      0.000578\n",
       "MTNC_Care          0.000574\n",
       "MOO                0.000524\n",
       "KeyBank_Help       0.000482\n",
       "AskSeagate         0.000473\n",
       "AskVirginMoney     0.000466\n",
       "OPPOCareIN         0.000428\n",
       "AskRobinhood       0.000392\n",
       "AskTigogh          0.000349\n",
       "JackBox            0.000253\n",
       "mediatemplehelp    0.000239\n",
       "AskDSC             0.000238\n",
       "CarlsJr            0.000174\n",
       "HotelTonightCX     0.000165\n",
       "OfficeSupport      0.000073\n",
       "Name: author_id_y, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbounds_and_outbounds.author_id_y.value_counts(normalize = True).tail(20) #108 companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "1efdae4f-8ff9-4242-be79-06916771da66",
    "_uuid": "44f124ae8898978cf5c1e571da976888f8229894"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing anonymized screen names in X...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a789b414e84bc78960aab92c21ea05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/794299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing anonymized screen names in Y...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951641c9f8d74944844029678416bd0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/794299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Replace anonymized screen names with common token @__sn__\n",
    "with open(r'./Emoji_Dict.p', 'rb') as fp:\n",
    "    Emoji_Dict = pickle.load(fp)\n",
    "    Emoji_Dict = {v: k for k, v in Emoji_Dict.items()}\n",
    "\n",
    "def sn_replace(match):\n",
    "    _sn = match.group(2).lower()\n",
    "    if not _sn.isnumeric():\n",
    "        # This is a company screen name\n",
    "        return match.group(1) + match.group(2)\n",
    "    return ' @__sn__'\n",
    "\n",
    "\n",
    "def replace_ID(text):\n",
    "    try:\n",
    "        if isinstance(text, str):\n",
    "            sn_re = re.compile('(\\W@|^@)([a-zA-Z0-9_]+)')\n",
    "            return sn_re.sub(sn_replace, text)\n",
    "        else:\n",
    "            raise ValueError()      \n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "def convert_emojis_to_word(text, emoji_dict):\n",
    "    try:\n",
    "        if isinstance(text, str):\n",
    "            for emot in Emoji_Dict:\n",
    "                text = re.sub(r'(' +emot+ ')', \"\".join(Emoji_Dict[emot].replace(\":\",\" \")),text)\n",
    "            return text\n",
    "        else:\n",
    "            raise ValueError()      \n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "\n",
    "def replace_URL(text):\n",
    "    try:\n",
    "        if isinstance(text, str):\n",
    "            pattern = r\"http\\S+|https\\S+|www\\S+\"\n",
    "            return re.sub(pattern, \"__URL__\", str(text))\n",
    "        else:\n",
    "            raise ValueError()      \n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "\n",
    "def clean_text(text, emoji_dict = Emoji_Dict):\n",
    "    try:\n",
    "        if isinstance(text, str):\n",
    "            temp1 = replace_ID(text)\n",
    "            temp2 = convert_emojis_to_word(temp1, emoji_dict)\n",
    "            temp3 = replace_URL(temp2)\n",
    "            return temp3   \n",
    "        else:\n",
    "            raise ValueError()      \n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108568    @ChipotleTweets my food fell out my bag...and ...\n",
       "277961    #weak @__sn__ #noshow #iphone Delivery after w...\n",
       "513149    Really wanted to preorder the IphoneX but with...\n",
       "160768    @TfL please could you get back to me about thi...\n",
       "159452    @hpsupport [How do I add my email accounts? It...\n",
       "130032    Would love to understand the point of Elite st...\n",
       "818094     @__sn__ is by far the worst provider ever! So...\n",
       "816839    I dig it when I get home to find that half my ...\n",
       "688930    @AmazonHelp pls help me i ordered a new pingpo...\n",
       "91484     Sooo my uber ride took about 40 minutes. I hav...\n",
       "Name: text_x, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_text = inbounds_and_outbounds.text_x.progress_apply(lambda txt: clean_text(txt))\n",
    "y_text = inbounds_and_outbounds.text_y.progress_apply(lambda txt: clean_text(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "eba2c6e6-f57e-438e-983f-d19c5156c817",
    "_uuid": "e3f3adeb6aebe8a90bdd7bfcd4fd6cff797d85ad",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CountVectorizer on X and Y text data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff12796862f045a1851d1895df95f642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/794299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JiatingChen\\anaconda3\\envs\\chatbot_venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned vocab of 8192 items.\n"
     ]
    }
   ],
   "source": [
    "count_vec = CountVectorizer(tokenizer=casual_tokenize, max_features=MAX_VOCAB_SIZE - 3)\n",
    "print(\"Fitting CountVectorizer on X and Y text data...\")\n",
    "count_vec.fit(tqdm(x_text + y_text))\n",
    "analyzer = count_vec.build_analyzer()\n",
    "vocab = {k: v + 3 for k, v in count_vec.vocabulary_.items()}\n",
    "vocab['__unk__'] = UNK\n",
    "vocab['__pad__'] = PAD\n",
    "vocab['__start__'] = START\n",
    "\n",
    "# Used to turn seq2seq predictions into human readable strings\n",
    "reverse_vocab = {v: k for k, v in vocab.items()}\n",
    "print(f\"Learned vocab of {len(vocab)} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108568    @ChipotleTweets my food fell out my bag...and ...\n",
       "277961    #weak @__sn__ #noshow #iphone Delivery after w...\n",
       "513149    Really wanted to preorder the IphoneX but with...\n",
       "160768    @TfL please could you get back to me about thi...\n",
       "159452    @hpsupport [How do I add my email accounts? It...\n",
       "                                ...                        \n",
       "861234     @__sn__ there is an $80 discrepancy between a...\n",
       "765002    For me @AldiUK is the winner for the Christmas...\n",
       "337319    @SW_Help what would off peak times be for tomo...\n",
       "567819    @ComcastCares\\n#mobile_CareXI having internet ...\n",
       "245074    Thank you crew of @SouthwestAir flight #675 fr...\n",
       "Length: 794299, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_text + y_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['__start__']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c01e85bb-974d-4bf3-8eb1-b5893ce8f284",
    "_uuid": "893cae536132c7477699350574f5de0fd7a60a3f"
   },
   "source": [
    "### Vocab Helper Functions\n",
    "These helper functions take strings and turn them into word indexes used by the actual seq2seq models.  This turns something like \"This is how we do it.\" into a padded array of integers, like [153, 4, 643, 48, 94, 54, 8, 0, 0, 0].  We'll apply the `to_word_idx` function to our text data to get our `N x MESSAGE_LEN` training/test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "d04887da-5ca9-4380-949e-7f7923a85df8",
    "_uuid": "b32c76052be9f5493b7eeee1cf40435e438eb3ca"
   },
   "outputs": [],
   "source": [
    "def to_word_idx(sentence):\n",
    "    full_length = [vocab.get(tok, UNK) for tok in analyzer(sentence)] + [PAD] * MAX_MESSAGE_LEN\n",
    "    return full_length[:MAX_MESSAGE_LEN]\n",
    "\n",
    "def from_word_idx(word_idxs):\n",
    "    return ' '.join(reverse_vocab[idx] for idx in word_idxs if idx != PAD).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108568    [487, 4876, 3022, 2914, 5184, 4876, 1111, 161,...\n",
       "277961    [0, 449, 0, 74, 2213, 685, 7628, 3547, 3027, 6...\n",
       "513149    [5826, 7643, 7207, 5579, 7088, 3969, 1440, 779...\n",
       "160768    [531, 5465, 1975, 7909, 3182, 1099, 7207, 4656...\n",
       "159452    [500, 545, 3551, 2416, 3763, 627, 4876, 2612, ...\n",
       "Name: text_x, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_text.head().apply(to_word_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "f4b791c1-48a3-4cff-895f-a9140a93c831",
    "_uuid": "3ac8190e6d5985151dbfd5a11a502a389279bad7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108568    @chipotletweets my food fell out my bag ... an...\n",
       "277961    __unk__ @__sn__ __unk__ #iphone delivery after...\n",
       "513149    really wanted to preorder the iphonex but with...\n",
       "160768    @tfl please could you get back to me about thi...\n",
       "159452    @hpsupport [ how do i add my email accounts ? ...\n",
       "Name: text_x, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure our helpers work as expected...\n",
    "x_text.head().apply(to_word_idx).apply(from_word_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "878"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['anyone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'anyone'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_vocab[878]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "d1977e30-2cc7-4786-91b2-10dbaa63f17d",
    "_uuid": "74951a1b74353c31e5e64a68d0f329f1efa9543d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating word indexes for X...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JiatingChen\\AppData\\Local\\Temp\\ipykernel_25720\\3937095903.py:2: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  x = pd.np.vstack(x_text.progress_apply(to_word_idx).values)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5551212ca3aa4665a140700b7c79ccc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/794299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating word indexes for Y...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JiatingChen\\AppData\\Local\\Temp\\ipykernel_25720\\3937095903.py:4: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  y = pd.np.vstack(y_text.progress_apply(to_word_idx).values)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d30fa843af4565b9e7aa842b7a335a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/794299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Calculating word indexes for X...\")\n",
    "x = pd.np.vstack(x_text.progress_apply(to_word_idx).values)\n",
    "print(\"Calculating word indexes for Y...\")\n",
    "y = pd.np.vstack(y_text.progress_apply(to_word_idx).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "edebf7ab-0495-4e38-9900-7a9652cdb2d0",
    "_uuid": "f9f842020ecb321805c9032d20b01f1ffe6f5885"
   },
   "source": [
    "### Train / Test Split\n",
    "Here, we split our data into training and test sets.  For simplicity, we use a random split, which may result in different distributions between the training and test set, but we won't worry about that for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "67b9f6e4-2619-48c9-9339-da6637e646d3",
    "_uuid": "d4f3b7134ac395a1952f8dc816cedad201cdf0a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data of shape (635439, 30) and test data of shape (158860, 30).\n"
     ]
    }
   ],
   "source": [
    "all_idx = list(range(len(x)))\n",
    "random.seed(1234)\n",
    "train_idx = set(random.sample(all_idx, int(0.8 * len(all_idx))))\n",
    "test_idx = {idx for idx in all_idx if idx not in train_idx}\n",
    "\n",
    "train_x = x[list(train_idx)]\n",
    "test_x = x[list(test_idx)]\n",
    "train_y = y[list(train_idx)]\n",
    "test_y = y[list(test_idx)]\n",
    "\n",
    "assert train_x.shape == train_y.shape\n",
    "assert test_x.shape == test_y.shape\n",
    "\n",
    "print(f'Training data of shape {train_x.shape} and test data of shape {test_x.shape}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 487, 4876, 3022, ...,    1,    1,    1],\n",
       "       [   0,  449,    0, ...,    1,    1,    1],\n",
       "       [5826, 7643, 7207, ...,    1,    1,    1],\n",
       "       ...,\n",
       "       [ 449, 7096, 3976, ..., 5465,  666,  966],\n",
       "       [ 488,   90, 3388, ...,    1,    1,    1],\n",
       "       [7075, 7909, 2032, ...,    1,    1,    1]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9764b6aa-13e3-409e-939e-64f7f7083350",
    "_uuid": "89c827fa1a1aabc990e6b04b4a4839bd04b9b42c"
   },
   "source": [
    "## Model Creation\n",
    "We'll create and compile the model here.  It will consist of the following components:\n",
    "\n",
    "- Shared word embeddings\n",
    "  - A shared embedding layer that turns word indexes (a sparse representation) into a dense/compressed representation.  This embeds both the request from the customer, and also the last words uttered by the model that are fed back into the model.\n",
    "- Encoder RNN\n",
    "  - In this case, a single LSTM layer.  This encodes the whole input sentence into a context vector (or thought vector) that represents completely what the customer is saying, and produces a single output.\n",
    "- Decoder RNN\n",
    "  - This RNN (also an LSTM in this case) decodes the context vector into a string of tokens/utterances.  For each time step, it takes the context vector and the embedded last utterance and produces the next utterance, which is fed back into the model.  More complex and effective models copy the encoder state into the decoder, add more layers of LSTMs, and apply attention mechanisms - but these are out of the scope of this simple example.\n",
    "- Next Word Dense+Softmax\n",
    "  - These two layers take the decoder output and turn it into the next word to be uttered.  The dense layer allows the decoder to not map directly to words uttered, and the softmax turns the dense layer output into a probability distribution, from which we pick the most likely next word.\n",
    "\n",
    "![seq2seq model structure](https://i.imgur.com/JmuryKu.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "ee656365-3b04-4dfc-a4dc-a4081ceea82d",
    "_uuid": "46bea6af349b1b67b870eb5977c2bd0c798e2b86"
   },
   "outputs": [],
   "source": [
    "# keras imports, because there are like... A million of them.\n",
    "from keras.models import Model\n",
    "# from keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Dense, Input, LSTM, Dropout, Embedding, RepeatVector, concatenate, \\\n",
    "     TimeDistributed\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# from tensorflow.keras import Model, Sequential\n",
    "# from tensorflow.keras.layers import Dense, Input, LSTM, Dropout, Embedding, RepeatVector, concatenate, \\\n",
    "#      TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.22.3'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_cell_guid": "d0a87457-573a-43b8-9a0a-d869a75b86ba",
    "_uuid": "420e809e7f3c9986bf4d3e3804198b8205e4a772",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JiatingChen\\anaconda3\\envs\\chatbot_venv\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    shared_embedding = Embedding(\n",
    "        output_dim=EMBEDDING_SIZE,\n",
    "        input_dim=MAX_VOCAB_SIZE,\n",
    "        input_length=MAX_MESSAGE_LEN,\n",
    "        name='embedding',\n",
    "    )\n",
    "    \n",
    "    # ENCODER\n",
    "    \n",
    "    encoder_input = Input(\n",
    "        shape=(MAX_MESSAGE_LEN,),\n",
    "        dtype='int32',\n",
    "        name='encoder_input',\n",
    "    )\n",
    "    \n",
    "    embedded_input = shared_embedding(encoder_input)\n",
    "    \n",
    "    # No return_sequences - since the encoder here only produces a single value for the\n",
    "    # input sequence provided.\n",
    "    encoder_rnn = LSTM(\n",
    "        CONTEXT_SIZE,\n",
    "        name='encoder',\n",
    "        dropout=DROPOUT\n",
    "    )\n",
    "    \n",
    "    context = RepeatVector(MAX_MESSAGE_LEN)(encoder_rnn(embedded_input))\n",
    "    \n",
    "    # DECODER\n",
    "    \n",
    "    last_word_input = Input(\n",
    "        shape=(MAX_MESSAGE_LEN, ),\n",
    "        dtype='int32',\n",
    "        name='last_word_input',\n",
    "    )\n",
    "    \n",
    "    embedded_last_word = shared_embedding(last_word_input)\n",
    "    # Combines the context produced by the encoder and the last word uttered as inputs\n",
    "    # to the decoder.\n",
    "    decoder_input = concatenate([embedded_last_word, context], axis=2)\n",
    "    \n",
    "    # return_sequences causes LSTM to produce one output per timestep instead of one at the\n",
    "    # end of the intput, which is important for sequence producing models.\n",
    "    decoder_rnn = LSTM(\n",
    "        CONTEXT_SIZE,\n",
    "        name='decoder',\n",
    "        return_sequences=True,\n",
    "        dropout=DROPOUT\n",
    "    )\n",
    "    \n",
    "    decoder_output = decoder_rnn(decoder_input)\n",
    "    \n",
    "    # TimeDistributed allows the dense layer to be applied to each decoder output per timestep\n",
    "    next_word_dense = TimeDistributed(\n",
    "        Dense(int(MAX_VOCAB_SIZE / 2), activation='relu'),\n",
    "        name='next_word_dense',\n",
    "    )(decoder_output)\n",
    "    \n",
    "    next_word = TimeDistributed(\n",
    "        Dense(MAX_VOCAB_SIZE, activation='softmax'),\n",
    "        name='next_word_softmax'\n",
    "    )(next_word_dense)\n",
    "    \n",
    "    return Model(inputs=[encoder_input, last_word_input], outputs=[next_word])\n",
    "\n",
    "s2s_model = create_model()\n",
    "optimizer = Adam(lr=LEARNING_RATE, clipvalue=5.0)\n",
    "s2s_model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "37dc7acc-ed74-4933-9182-b4329258d31f",
    "_uuid": "261fdad98295fa395592a5a6bf60806151a51c74"
   },
   "source": [
    "## Model Training\n",
    "We'll train the model here.  After each sub-batch of the dataset, we'll test with static input strings to see how the model is progressing in human readable terms.  Its important to have these tests along with traditional model evaluation to provide a better understanding of how well the model is training.\n",
    "\n",
    "It's important to pull test strings from the real distribution of the data, also.  It can be hard to really put yourself in customers' shoes when writing test messages, and you will get non-representative results when you provide test examples that don't fit the true distribution of the input data (when your input text doesn't sound like real customer requests)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_cell_guid": "db2eee93-8070-4572-962e-c7225b20d2e4",
    "_uuid": "464355ec34af2c192723e66222c036826ac323f7"
   },
   "outputs": [],
   "source": [
    "def add_start_token(y_array):\n",
    "    \"\"\" Adds the start token to vectors.  Used for training data. \"\"\"\n",
    "    return np.hstack([\n",
    "        START * np.ones((len(y_array), 1)),\n",
    "        y_array[:, :-1],\n",
    "    ])\n",
    "\n",
    "def binarize_labels(labels):\n",
    "    \"\"\" Helper function that turns integer word indexes into sparse binary matrices for \n",
    "        the expected model output.\n",
    "    \"\"\"\n",
    "    return np.array([np_utils.to_categorical(row, num_classes=MAX_VOCAB_SIZE)\n",
    "                     for row in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_cell_guid": "ce33ef3c-90df-4d3f-aad7-82db7b8cbf38",
    "_uuid": "982ca948fcf372ba6d29cc1872b9667c8e7c678f"
   },
   "outputs": [],
   "source": [
    "def respond_to(model, text):\n",
    "    \"\"\" Helper function that takes a text input and provides a text output. \"\"\"\n",
    "    input_y = add_start_token(PAD * np.ones((1, MAX_MESSAGE_LEN)))\n",
    "    idxs = np.array(to_word_idx(text)).reshape((1, MAX_MESSAGE_LEN))\n",
    "    for position in range(MAX_MESSAGE_LEN - 1):\n",
    "        prediction = model.predict([idxs, input_y]).argmax(axis=2)[0]\n",
    "        input_y[:,position + 1] = prediction[position]\n",
    "    return from_word_idx(model.predict([idxs, input_y]).argmax(axis=2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_cell_guid": "3fb77b82-c4c3-4328-89a9-4c679744018c",
    "_uuid": "134fb65418234dd849a6d0147f95728373ea80a0"
   },
   "outputs": [],
   "source": [
    "def train_mini_epoch(model, start_idx, end_idx):\n",
    "    \"\"\" Batching seems necessary in Kaggle Jupyter Notebook environments, since\n",
    "        `model.fit` seems to freeze on larger batches (somewhere 1k-10k).\n",
    "    \"\"\"\n",
    "    b_train_y = binarize_labels(train_y[start_idx:end_idx])\n",
    "    input_train_y = add_start_token(train_y[start_idx:end_idx])\n",
    "    \n",
    "    model.fit(\n",
    "        [train_x[start_idx:end_idx], input_train_y], \n",
    "        b_train_y,\n",
    "        epochs=1,\n",
    "        batch_size=BATCH_SIZE,\n",
    "    )\n",
    "    \n",
    "    rand_idx = random.sample(list(range(len(test_x))), SUB_BATCH_SIZE)\n",
    "    print('Test results:', model.evaluate(\n",
    "        [test_x[rand_idx], add_start_token(test_y[rand_idx])],\n",
    "        binarize_labels(test_y[rand_idx])\n",
    "    ))\n",
    "    \n",
    "    input_strings = [\n",
    "        \"@AppleSupport I fix I this I stupid I problem I\",\n",
    "        \"@AmazonHelp I hadnt expected that such a big brand like amazon would have such a poor customer service.\",\n",
    "    ]\n",
    "    \n",
    "    for input_string in input_strings:\n",
    "        output_string = respond_to(model, input_string)\n",
    "        print(f'> \"{input_string}\"\\n< \"{output_string}\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8a481fec-429a-45c5-bbb7-5f8f7e0e2487",
    "_uuid": "00e0850fe55d06f6d86c71c055ee45d8a0086c21"
   },
   "source": [
    "### Train the model!\n",
    "\n",
    "You can stop training by pressing the stop button - the training code is configured to watch for the `KeyboardInterrupt` exception triggered that way.  Also, it will run until the configured stopping point below.\n",
    "\n",
    "\n",
    "Let's start the training! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "450d8fd0-25b2-41cb-ad3b-dbb266568b72",
    "_uuid": "790bb2978f320f7988f0e850026f264a434b5c3e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_time_limit = 360 * 60  # seconds (notebooks terminate after 1 hour)\n",
    "start_time = time.time()\n",
    "stop_after = start_time + training_time_limit\n",
    "\n",
    "class TimesUpInterrupt(Exception):\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    for epoch in range(2):\n",
    "        print(f'Training in epoch {epoch}...')\n",
    "        for start_idx in range(0, len(train_x), SUB_BATCH_SIZE):\n",
    "            train_mini_epoch(s2s_model, start_idx, start_idx + SUB_BATCH_SIZE)\n",
    "            if time.time() > stop_after:\n",
    "                raise TimesUpInterrupt\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Halting training from keyboard interrupt.\")\n",
    "except TimesUpInterrupt:\n",
    "    print(f\"Halting after {time.time() - start_time} seconds spent training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "18a421a1-41d7-4c87-988d-74fa8dc85992",
    "_uuid": "8ebd6c01cd3a7e75810f9fc48b4d2ad913f9f410"
   },
   "outputs": [],
   "source": [
    "respond_to(s2s_model, '''@AppleSupport iPhone 8 touchID doesnt unlock while charging on \n",
    "    110v w/ 61w laptop charger to usbc lightning cable just uh.. so you guys know''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eef56338-516e-46ed-94d5-6c7d21279d34",
    "_uuid": "e5f0a5acf6611334291cea8c3440c5dd3badf2f0"
   },
   "outputs": [],
   "source": [
    "respond_to(s2s_model, '''@sprintcare I can't make calls... wtf''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respond_to(s2s_model, '''''@sprintcare is the worst customer service''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respond_to(s2s_model, '''''@VerizonSupport My friend is without internet we need to play videogames together please our skills diminish every moment without internet''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respond_to(s2s_model, '''@XboxSupport can I change me sons Xbox live account to his Hotmail account, currently linked to my Hotmail account''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respond_to(s2s_model, \"\"\"@116297 Very disappointed in your service to me as a customer of many years.  Again issues with you your customer service department. They promise one thing and do another. I guess Fool me once, shame on you. Fool me twice, shame on me.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1445794c-c26f-4dc9-a38e-90b98ee206cb",
    "_uuid": "f7e4303f8ee7d2def95c95b166b6fac8727217f5"
   },
   "outputs": [],
   "source": [
    "#s2s_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2s_model.save(\"../model/s2s_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "# tf.keras.utils.plot_model(s2s_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " last_word_input (InputLayer)   [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " encoder_input (InputLayer)     [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 30, 100)      819200      ['encoder_input[0][0]',          \n",
      "                                                                  'last_word_input[0][0]']        \n",
      "                                                                                                  \n",
      " encoder (LSTM)                 (None, 100)          80400       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVector)   (None, 30, 100)      0           ['encoder[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 30, 200)      0           ['embedding[1][0]',              \n",
      "                                                                  'repeat_vector[0][0]']          \n",
      "                                                                                                  \n",
      " decoder (LSTM)                 (None, 30, 100)      120400      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " next_word_dense (TimeDistribut  (None, 30, 4096)    413696      ['decoder[0][0]']                \n",
      " ed)                                                                                              \n",
      "                                                                                                  \n",
      " next_word_softmax (TimeDistrib  (None, 30, 8192)    33562624    ['next_word_dense[0][0]']        \n",
      " uted)                                                                                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 34,996,320\n",
      "Trainable params: 34,996,320\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "s2s_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    '../model/s2s_model.h5'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@__sn__ hi there , we are sorry to hear this . please dm us your account details so we can look into this for you . ^ mw'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond_to(model, \"@AppleSupport testing testing!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
