{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "#pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('C:\\\\Users\\\\JiatingChen\\\\Documents\\\\archive\\\\twcs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"C:\\\\Users\\\\JiatingChen\\\\Documents\\\\archive\\\\twcs\\\\twcs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"text\"] = tweets[\"text\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.shape #2,811,774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.sort_values('tweet_id').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_response_tweet_id = 1: tweet_id = 1 is the prior sentense\n",
    "# response_tweet_id = 1: tweet_id = 1 is the next sentense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_inbound = tweets[pd.isnull(tweets.in_response_to_tweet_id)] #initize the conversation\n",
    "inbounds_and_outbounds = pd.merge(first_inbound, tweets, left_on='tweet_id', \n",
    "                                  right_on='in_response_to_tweet_id') \n",
    "inbounds_and_outbounds.sort_values(['tweet_id_x', 'created_at_y'], ascending= [True, True]).shape #895,514 back-and-forth dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inbounds_and_outbounds.head(100).created_at_y = pd.to_datetime(inbounds_and_outbounds.head(100).created_at_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inbounds_and_outbounds.head(100).sort_values(['tweet_id_x', 'created_at_y'], ascending= [True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inbounds_and_outbounds.head(100).sort_values(['tweet_id_x', 'created_at_y'], ascending= [True, True])[['text_x', 'text_y']].head(100).to_csv('conv.txt', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inbounds_and_outbounds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inbounds_and_outbounds[['text_x', 'text_y']].head(100).to_csv('conv.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_inbound2 = tweets[pd.isnull(tweets.in_response_to_tweet_id) & tweets.inbound]\n",
    "inbounds_and_outbounds = pd.merge(first_inbound2, tweets, left_on='tweet_id', \n",
    "                                  right_on='in_response_to_tweet_id') #.sample(frac=1)\n",
    "inbounds_and_outbounds2 = inbounds_and_outbounds[inbounds_and_outbounds.inbound_y ^ True]\n",
    "inbounds_and_outbounds2.sort_values('tweet_id_x').shape #794,299 back-and-forth dialog responded from companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## citation: https://www.kaggle.com/soaxelbrooke/twitter-basic-seq2seq\n",
    "## next step 1 - text preprocessing\n",
    "- Lower casing\n",
    "- Removal of Punctuations\n",
    "- Removal of Stopwords\n",
    "- Removal of Frequent words\n",
    "- Removal of Rare words\n",
    "- Stemming\n",
    "- Lemmatization\n",
    "- Removal of emojis\n",
    "- Removal of emoticons\n",
    "- Conversion of emoticons to words\n",
    "- Conversion of emojis to words\n",
    "- Removal of URLs\n",
    "- Removal of HTML tags\n",
    "- Chat words conversion\n",
    "- Spelling correction\n",
    "\n",
    "## next step 2 - build virtualenv for all necessary packages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
